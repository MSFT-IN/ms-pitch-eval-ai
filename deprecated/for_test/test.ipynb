{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Using cached dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting python-dotenv (from dotenv)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: urllib3, python-dotenv, idna, charset-normalizer, certifi, requests, dotenv\n",
      "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 dotenv-0.9.9 idna-3.10 python-dotenv-1.0.1 requests-2.32.3 urllib3-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install dotenv requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "AUDIO_FILE_PATH = os.getenv(\"AUDIO_FILE_PATH\")\n",
    "AUDIO_FILE_NAME = os.getenv(\"AUDIO_FILE_NAME\")\n",
    "AOAI_ENDPOINT_GPT = os.getenv(\"AOAI_ENDPOINT_GPT\")\n",
    "AOAI_ENDPOINT_GPT_0513 = os.getenv(\"AOAI_ENDPOINT_GPT_0513\")\n",
    "AOAI_ENDPOINT_WHISPER = os.getenv(\"AOAI_ENDPOINT_WHISPER\")\n",
    "AOAI_API_KEY = os.getenv(\"AOAI_API_KEY\")\n",
    "\n",
    "AI_SERVICES_SPEECH_KEY = os.getenv(\"AI_SERVICES_SPEECH_KEY\")\n",
    "AI_SERVICES_SPEECH_REGION = os.getenv(\"AI_SERVICES_SPEECH_REGION\")\n",
    "AI_SERVICES_SPEECH_ENDPOINT = os.getenv(\"AI_SERVICES_SPEECH_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.65.4-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached jiter-0.8.2-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached pydantic_core-2.27.2-cp313-cp313-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.65.4-py3-none-any.whl (473 kB)\n",
      "Using cached anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached jiter-0.8.2-cp313-cp313-win_amd64.whl (203 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: typing-extensions, tqdm, sniffio, jiter, h11, distro, annotated-types, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.8.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.8.2 openai-1.65.4 pydantic-2.10.6 pydantic-core-2.27.2 sniffio-1.3.1 tqdm-4.67.1 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "def call_whisper(audio_file_path):\n",
    "    \"\"\"\n",
    "    Function to convert audio to text using Whisper audio transcription.\n",
    "    \n",
    "    Args:\n",
    "        audio_file_path (str): Path to the audio file, including the file name and extension. e.g., \"testfiles/testaudio.mp3\"\n",
    "    Returns:\n",
    "        result (str): STT result text.\n",
    "    \n",
    "    * Uses Azure AI Services OpenAI\n",
    "    * Reference https://learn.microsoft.com/en-us/azure/ai-services/openai/whisper-quickstart?tabs=command-line%2Cpython-new%2Ckeyless%2Ctypescript-keyless&pivots=programming-language-python\n",
    "    \"\"\"\n",
    "     \n",
    "    aoai_client_whisper = AzureOpenAI(\n",
    "        api_key = os.getenv(\"AOAI_API_KEY\"),  \n",
    "        api_version = \"2024-02-01\",\n",
    "        azure_endpoint = os.getenv(\"AOAI_ENDPOINT_WHISPER\")\n",
    "    )\n",
    "\n",
    "    response = aoai_client_whisper.audio.transcriptions.create(\n",
    "        file = open(audio_file_path, \"rb\"),            \n",
    "        model = \"whisper\",\n",
    "        response_format = \"verbose_json\"\n",
    "    )\n",
    "\n",
    "    result = response.text\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TranscriptionVerbose(duration=326.30999755859375, language='english', text=\"Hello, I am Sang-Jun Park, who is in charge of strategic implementation and business operations in security at Microsoft Korea. Today, I would like to explain how to support multi-cloud DevOps through Microsoft Copilot for Security in various security sessions of Build. Before we start the session, I need to explain about Copilot for Security. For those of you who don't know about Copilot for Security, let me briefly explain. It is the world's first and only AI-based security solution based on GPT-4. We released a preview about a year ago, and it was officially introduced in April this year. It is a solution that can innovatively raise the level of customer cyber security through AI. It is based on enormous data. Copilot for Security was learned through about 65 security signals. We support you with machine speed and scale through this. What this means is that we help customers through very fast speed and scale. It is like putting a super-high-end or medium-end security engine next to us, learning simple things from them, and helping us with our work. Unlike conventional AI, this is provided exclusively for companies. Also, customer data is not used for AI learning. So, you can use AI without worrying about customer data leakage. Of course, in this build, the product linked to Copilot for Security has been expanded. We call it MDC. It has been expanded to Defender for Cloud. This time, it is still a public preview. I will give you a detailed explanation of this. First, let me tell you about the operation method. As you can see from the title, it is machine speed and scale. As I said, it has very fast speed and scalability. In general, security workers can complete their work in a few minutes in a few hours or a few days. This means that we have expanded these capabilities to MDC. If you look at the left, there are three benefits. First, you can simplify complicated things. In fact, there are a lot of security signals, but you can easily classify and respond by reducing these noises and using self-data. The second feature is to detect without missing. If you use Copilot and MDC together, security managers can capture everything without missing by filtering the noise and modify it quickly to simplify the complexity. Finally, it is to respond quickly. In order to solve problems on the source code, AI provides a solution action. Through this, you can quickly solve the problem. I'll give you a detailed explanation of this next time. First, the first feature is to find out the risk. It can quickly tell you what is important and dangerous in the customer cloud environment. First, if you look at the right screen, the left is the MDC screen and the right is the Copilot screen embedded. And if you look at the top, there are various sources such as Azure, GCP, AWS. So, if the MDC on the left captures information about security risks, the Copilot on the right can ask more detailed questions, analyze, and respond. And as an example, I told you to summarize the contents on the left, and the right tells you those contents and provides insights. The second feature is Risk Remediation. It helps you respond to risks. So, using the AI-integrated remediation function, you can receive a warning, read it, understand the content, and take the necessary action. If you look at the right screen for a moment, you can see a summary and insight on the current situation on the previous screen. This time, I told the Copilot to ask where the resources related to vulnerability are, and I asked him to focus on that a little more. You can see that the Copilot is telling you about this. Lastly, there is the automated threat remediation function. It uses the full request function created by the AI to correct code miscomplications on DevOps. If you look at the right on the left, it asks if you will submit a full request to solve the problem on Azure DevOps. So, if you submit this, the contents will be updated to Azure DevOps and you can correct the wrong explanation. To sum up, you can quickly understand the current situation through MDC and Copilot, and you can get a guide and automated solution to solve the problem. Through this, you can operate security more smartly than before. This is the effect you can get by linking Copilot for Security, an AI solution, and Microsoft Vendor for Cloud for cloud security. That's it for today's explanation. Please continue to pay attention to Microsoft security. Thank you for listening.\", segments=[TranscriptionSegment(id=0, avg_logprob=-0.6834016442298889, compression_ratio=1.4136126041412354, end=17.0, no_speech_prob=0.033493056893348694, seek=0, start=0.0, temperature=0.0, text=' Hello, I am Sang-Jun Park, who is in charge of strategic implementation and business operations in security at Microsoft Korea.', tokens=[50364, 2425, 11, 286, 669, 19037, 12, 41, 409, 4964, 11, 567, 307, 294, 4602, 295, 10924, 566, 781, 19631, 293, 1606, 7705, 294, 3825, 412, 8116, 6307, 13, 51214]), TranscriptionSegment(id=1, avg_logprob=-0.6834016442298889, compression_ratio=1.4136126041412354, end=29.0, no_speech_prob=0.033493056893348694, seek=0, start=17.0, temperature=0.0, text=' Today, I would like to explain how to support multi-cloud DevOps through Microsoft Copilot for Security in various security sessions of Build.', tokens=[51214, 2692, 11, 286, 576, 411, 281, 2903, 577, 281, 1406, 4825, 12, 44495, 43051, 807, 8116, 11579, 31516, 337, 11164, 294, 3683, 3825, 11081, 295, 11875, 13, 51814]), TranscriptionSegment(id=2, avg_logprob=-0.4305660128593445, compression_ratio=1.5497630834579468, end=35.0, no_speech_prob=0.003477872582152486, seek=2900, start=30.0, temperature=0.0, text=' Before we start the session, I need to explain about Copilot for Security.', tokens=[50414, 4546, 321, 722, 264, 5481, 11, 286, 643, 281, 2903, 466, 11579, 31516, 337, 11164, 13, 50664]), TranscriptionSegment(id=3, avg_logprob=-0.4305660128593445, compression_ratio=1.5497630834579468, end=41.0, no_speech_prob=0.003477872582152486, seek=2900, start=35.0, temperature=0.0, text=\" For those of you who don't know about Copilot for Security, let me briefly explain.\", tokens=[50664, 1171, 729, 295, 291, 567, 500, 380, 458, 466, 11579, 31516, 337, 11164, 11, 718, 385, 10515, 2903, 13, 50964]), TranscriptionSegment(id=4, avg_logprob=-0.4305660128593445, compression_ratio=1.5497630834579468, end=47.0, no_speech_prob=0.003477872582152486, seek=2900, start=41.0, temperature=0.0, text=\" It is the world's first and only AI-based security solution based on GPT-4.\", tokens=[50964, 467, 307, 264, 1002, 311, 700, 293, 787, 7318, 12, 6032, 3825, 3827, 2361, 322, 26039, 51, 12, 19, 13, 51264]), TranscriptionSegment(id=5, avg_logprob=-0.4305660128593445, compression_ratio=1.5497630834579468, end=53.0, no_speech_prob=0.003477872582152486, seek=2900, start=47.0, temperature=0.0, text=' We released a preview about a year ago, and it was officially introduced in April this year.', tokens=[51264, 492, 4736, 257, 14281, 466, 257, 1064, 2057, 11, 293, 309, 390, 12053, 7268, 294, 6929, 341, 1064, 13, 51564]), TranscriptionSegment(id=6, avg_logprob=-0.447142094373703, compression_ratio=1.6218905448913574, end=60.0, no_speech_prob=0.31571003794670105, seek=5300, start=54.0, temperature=0.0, text=' It is a solution that can innovatively raise the level of customer cyber security through AI.', tokens=[50414, 467, 307, 257, 3827, 300, 393, 12999, 356, 5300, 264, 1496, 295, 5474, 13411, 3825, 807, 7318, 13, 50714]), TranscriptionSegment(id=7, avg_logprob=-0.447142094373703, compression_ratio=1.6218905448913574, end=64.0, no_speech_prob=0.31571003794670105, seek=5300, start=60.0, temperature=0.0, text=' It is based on enormous data.', tokens=[50714, 467, 307, 2361, 322, 11322, 1412, 13, 50914]), TranscriptionSegment(id=8, avg_logprob=-0.447142094373703, compression_ratio=1.6218905448913574, end=69.0, no_speech_prob=0.31571003794670105, seek=5300, start=64.0, temperature=0.0, text=' Copilot for Security was learned through about 65 security signals.', tokens=[50914, 11579, 31516, 337, 11164, 390, 3264, 807, 466, 11624, 3825, 12354, 13, 51164]), TranscriptionSegment(id=9, avg_logprob=-0.447142094373703, compression_ratio=1.6218905448913574, end=73.0, no_speech_prob=0.31571003794670105, seek=5300, start=69.0, temperature=0.0, text=' We support you with machine speed and scale through this.', tokens=[51164, 492, 1406, 291, 365, 3479, 3073, 293, 4373, 807, 341, 13, 51364]), TranscriptionSegment(id=10, avg_logprob=-0.447142094373703, compression_ratio=1.6218905448913574, end=79.0, no_speech_prob=0.31571003794670105, seek=5300, start=73.0, temperature=0.0, text=' What this means is that we help customers through very fast speed and scale.', tokens=[51364, 708, 341, 1355, 307, 300, 321, 854, 4581, 807, 588, 2370, 3073, 293, 4373, 13, 51664]), TranscriptionSegment(id=11, avg_logprob=-0.514525830745697, compression_ratio=1.5308057069778442, end=83.0, no_speech_prob=0.002886695321649313, seek=7900, start=79.0, temperature=0.0, text=' It is like putting a super-high-end or medium-end security engine next to us,', tokens=[50364, 467, 307, 411, 3372, 257, 1687, 12, 21454, 12, 521, 420, 6399, 12, 521, 3825, 2848, 958, 281, 505, 11, 50564]), TranscriptionSegment(id=12, avg_logprob=-0.514525830745697, compression_ratio=1.5308057069778442, end=90.0, no_speech_prob=0.002886695321649313, seek=7900, start=83.0, temperature=0.0, text=' learning simple things from them, and helping us with our work.', tokens=[50564, 2539, 2199, 721, 490, 552, 11, 293, 4315, 505, 365, 527, 589, 13, 50914]), TranscriptionSegment(id=13, avg_logprob=-0.514525830745697, compression_ratio=1.5308057069778442, end=95.0, no_speech_prob=0.002886695321649313, seek=7900, start=90.0, temperature=0.0, text=' Unlike conventional AI, this is provided exclusively for companies.', tokens=[50914, 17657, 16011, 7318, 11, 341, 307, 5649, 20638, 337, 3431, 13, 51164]), TranscriptionSegment(id=14, avg_logprob=-0.514525830745697, compression_ratio=1.5308057069778442, end=98.0, no_speech_prob=0.002886695321649313, seek=7900, start=95.0, temperature=0.0, text=' Also, customer data is not used for AI learning.', tokens=[51164, 2743, 11, 5474, 1412, 307, 406, 1143, 337, 7318, 2539, 13, 51314]), TranscriptionSegment(id=15, avg_logprob=-0.514525830745697, compression_ratio=1.5308057069778442, end=104.0, no_speech_prob=0.002886695321649313, seek=7900, start=98.0, temperature=0.0, text=' So, you can use AI without worrying about customer data leakage.', tokens=[51314, 407, 11, 291, 393, 764, 7318, 1553, 18788, 466, 5474, 1412, 47799, 13, 51614]), TranscriptionSegment(id=16, avg_logprob=-0.3554612100124359, compression_ratio=1.6194331645965576, end=109.0, no_speech_prob=0.02400127798318863, seek=10400, start=104.0, temperature=0.0, text=' Of course, in this build, the product linked to Copilot for Security has been expanded.', tokens=[50364, 2720, 1164, 11, 294, 341, 1322, 11, 264, 1674, 9408, 281, 11579, 31516, 337, 11164, 575, 668, 14342, 13, 50614]), TranscriptionSegment(id=17, avg_logprob=-0.3554612100124359, compression_ratio=1.6194331645965576, end=111.0, no_speech_prob=0.02400127798318863, seek=10400, start=109.0, temperature=0.0, text=' We call it MDC.', tokens=[50614, 492, 818, 309, 22521, 34, 13, 50714]), TranscriptionSegment(id=18, avg_logprob=-0.3554612100124359, compression_ratio=1.6194331645965576, end=114.0, no_speech_prob=0.02400127798318863, seek=10400, start=111.0, temperature=0.0, text=' It has been expanded to Defender for Cloud.', tokens=[50714, 467, 575, 668, 14342, 281, 9548, 3216, 337, 8061, 13, 50864]), TranscriptionSegment(id=19, avg_logprob=-0.3554612100124359, compression_ratio=1.6194331645965576, end=116.0, no_speech_prob=0.02400127798318863, seek=10400, start=114.0, temperature=0.0, text=' This time, it is still a public preview.', tokens=[50864, 639, 565, 11, 309, 307, 920, 257, 1908, 14281, 13, 50964]), TranscriptionSegment(id=20, avg_logprob=-0.3554612100124359, compression_ratio=1.6194331645965576, end=119.0, no_speech_prob=0.02400127798318863, seek=10400, start=116.0, temperature=0.0, text=' I will give you a detailed explanation of this.', tokens=[50964, 286, 486, 976, 291, 257, 9942, 10835, 295, 341, 13, 51114]), TranscriptionSegment(id=21, avg_logprob=-0.3554612100124359, compression_ratio=1.6194331645965576, end=122.0, no_speech_prob=0.02400127798318863, seek=10400, start=119.0, temperature=0.0, text=' First, let me tell you about the operation method.', tokens=[51114, 2386, 11, 718, 385, 980, 291, 466, 264, 6916, 3170, 13, 51264]), TranscriptionSegment(id=22, avg_logprob=-0.3554612100124359, compression_ratio=1.6194331645965576, end=125.0, no_speech_prob=0.02400127798318863, seek=10400, start=122.0, temperature=0.0, text=' As you can see from the title, it is machine speed and scale.', tokens=[51264, 1018, 291, 393, 536, 490, 264, 4876, 11, 309, 307, 3479, 3073, 293, 4373, 13, 51414]), TranscriptionSegment(id=23, avg_logprob=-0.3554612100124359, compression_ratio=1.6194331645965576, end=129.0, no_speech_prob=0.02400127798318863, seek=10400, start=125.0, temperature=0.0, text=' As I said, it has very fast speed and scalability.', tokens=[51414, 1018, 286, 848, 11, 309, 575, 588, 2370, 3073, 293, 15664, 2310, 13, 51614]), TranscriptionSegment(id=24, avg_logprob=-0.5105962753295898, compression_ratio=1.621848702430725, end=134.0, no_speech_prob=0.31649285554885864, seek=12900, start=129.0, temperature=0.0, text=' In general, security workers can complete their work in a few minutes', tokens=[50364, 682, 2674, 11, 3825, 5600, 393, 3566, 641, 589, 294, 257, 1326, 2077, 50614]), TranscriptionSegment(id=25, avg_logprob=-0.5105962753295898, compression_ratio=1.621848702430725, end=137.0, no_speech_prob=0.31649285554885864, seek=12900, start=134.0, temperature=0.0, text=' in a few hours or a few days.', tokens=[50614, 294, 257, 1326, 2496, 420, 257, 1326, 1708, 13, 50764]), TranscriptionSegment(id=26, avg_logprob=-0.5105962753295898, compression_ratio=1.621848702430725, end=141.0, no_speech_prob=0.31649285554885864, seek=12900, start=137.0, temperature=0.0, text=' This means that we have expanded these capabilities to MDC.', tokens=[50764, 639, 1355, 300, 321, 362, 14342, 613, 10862, 281, 22521, 34, 13, 50964]), TranscriptionSegment(id=27, avg_logprob=-0.5105962753295898, compression_ratio=1.621848702430725, end=143.0, no_speech_prob=0.31649285554885864, seek=12900, start=141.0, temperature=0.0, text=' If you look at the left, there are three benefits.', tokens=[50964, 759, 291, 574, 412, 264, 1411, 11, 456, 366, 1045, 5311, 13, 51064]), TranscriptionSegment(id=28, avg_logprob=-0.5105962753295898, compression_ratio=1.621848702430725, end=147.0, no_speech_prob=0.31649285554885864, seek=12900, start=143.0, temperature=0.0, text=' First, you can simplify complicated things.', tokens=[51064, 2386, 11, 291, 393, 20460, 6179, 721, 13, 51264]), TranscriptionSegment(id=29, avg_logprob=-0.5105962753295898, compression_ratio=1.621848702430725, end=149.0, no_speech_prob=0.31649285554885864, seek=12900, start=147.0, temperature=0.0, text=' In fact, there are a lot of security signals,', tokens=[51264, 682, 1186, 11, 456, 366, 257, 688, 295, 3825, 12354, 11, 51364]), TranscriptionSegment(id=30, avg_logprob=-0.5105962753295898, compression_ratio=1.621848702430725, end=155.0, no_speech_prob=0.31649285554885864, seek=12900, start=149.0, temperature=0.0, text=' but you can easily classify and respond by reducing these noises and using self-data.', tokens=[51364, 457, 291, 393, 3612, 33872, 293, 4196, 538, 12245, 613, 14620, 293, 1228, 2698, 12, 67, 3274, 13, 51664]), TranscriptionSegment(id=31, avg_logprob=-0.42386698722839355, compression_ratio=1.532710313796997, end=159.0, no_speech_prob=0.001169073861092329, seek=15500, start=155.0, temperature=0.0, text=' The second feature is to detect without missing.', tokens=[50364, 440, 1150, 4111, 307, 281, 5531, 1553, 5361, 13, 50564]), TranscriptionSegment(id=32, avg_logprob=-0.42386698722839355, compression_ratio=1.532710313796997, end=162.0, no_speech_prob=0.001169073861092329, seek=15500, start=159.0, temperature=0.0, text=' If you use Copilot and MDC together,', tokens=[50564, 759, 291, 764, 11579, 31516, 293, 22521, 34, 1214, 11, 50714]), TranscriptionSegment(id=33, avg_logprob=-0.42386698722839355, compression_ratio=1.532710313796997, end=169.0, no_speech_prob=0.001169073861092329, seek=15500, start=162.0, temperature=0.0, text=' security managers can capture everything without missing by filtering the noise', tokens=[50714, 3825, 14084, 393, 7983, 1203, 1553, 5361, 538, 30822, 264, 5658, 51064]), TranscriptionSegment(id=34, avg_logprob=-0.42386698722839355, compression_ratio=1.532710313796997, end=172.0, no_speech_prob=0.001169073861092329, seek=15500, start=169.0, temperature=0.0, text=' and modify it quickly to simplify the complexity.', tokens=[51064, 293, 16927, 309, 2661, 281, 20460, 264, 14024, 13, 51214]), TranscriptionSegment(id=35, avg_logprob=-0.42386698722839355, compression_ratio=1.532710313796997, end=175.0, no_speech_prob=0.001169073861092329, seek=15500, start=172.0, temperature=0.0, text=' Finally, it is to respond quickly.', tokens=[51214, 6288, 11, 309, 307, 281, 4196, 2661, 13, 51364]), TranscriptionSegment(id=36, avg_logprob=-0.42386698722839355, compression_ratio=1.532710313796997, end=179.0, no_speech_prob=0.001169073861092329, seek=15500, start=175.0, temperature=0.0, text=' In order to solve problems on the source code,', tokens=[51364, 682, 1668, 281, 5039, 2740, 322, 264, 4009, 3089, 11, 51564]), TranscriptionSegment(id=37, avg_logprob=-0.42386698722839355, compression_ratio=1.532710313796997, end=182.0, no_speech_prob=0.001169073861092329, seek=15500, start=179.0, temperature=0.0, text=' AI provides a solution action.', tokens=[51564, 7318, 6417, 257, 3827, 3069, 13, 51714]), TranscriptionSegment(id=38, avg_logprob=-0.40242108702659607, compression_ratio=1.6679389476776123, end=185.0, no_speech_prob=0.35449427366256714, seek=18200, start=182.0, temperature=0.0, text=' Through this, you can quickly solve the problem.', tokens=[50364, 8927, 341, 11, 291, 393, 2661, 5039, 264, 1154, 13, 50514]), TranscriptionSegment(id=39, avg_logprob=-0.40242108702659607, compression_ratio=1.6679389476776123, end=188.0, no_speech_prob=0.35449427366256714, seek=18200, start=185.0, temperature=0.0, text=\" I'll give you a detailed explanation of this next time.\", tokens=[50514, 286, 603, 976, 291, 257, 9942, 10835, 295, 341, 958, 565, 13, 50664]), TranscriptionSegment(id=40, avg_logprob=-0.40242108702659607, compression_ratio=1.6679389476776123, end=191.0, no_speech_prob=0.35449427366256714, seek=18200, start=188.0, temperature=0.0, text=' First, the first feature is to find out the risk.', tokens=[50664, 2386, 11, 264, 700, 4111, 307, 281, 915, 484, 264, 3148, 13, 50814]), TranscriptionSegment(id=41, avg_logprob=-0.40242108702659607, compression_ratio=1.6679389476776123, end=197.0, no_speech_prob=0.35449427366256714, seek=18200, start=191.0, temperature=0.0, text=' It can quickly tell you what is important and dangerous in the customer cloud environment.', tokens=[50814, 467, 393, 2661, 980, 291, 437, 307, 1021, 293, 5795, 294, 264, 5474, 4588, 2823, 13, 51114]), TranscriptionSegment(id=42, avg_logprob=-0.40242108702659607, compression_ratio=1.6679389476776123, end=201.0, no_speech_prob=0.35449427366256714, seek=18200, start=197.0, temperature=0.0, text=' First, if you look at the right screen, the left is the MDC screen', tokens=[51114, 2386, 11, 498, 291, 574, 412, 264, 558, 2568, 11, 264, 1411, 307, 264, 22521, 34, 2568, 51314]), TranscriptionSegment(id=43, avg_logprob=-0.40242108702659607, compression_ratio=1.6679389476776123, end=204.0, no_speech_prob=0.35449427366256714, seek=18200, start=201.0, temperature=0.0, text=' and the right is the Copilot screen embedded.', tokens=[51314, 293, 264, 558, 307, 264, 11579, 31516, 2568, 16741, 13, 51464]), TranscriptionSegment(id=44, avg_logprob=-0.40242108702659607, compression_ratio=1.6679389476776123, end=209.0, no_speech_prob=0.35449427366256714, seek=18200, start=204.0, temperature=0.0, text=' And if you look at the top, there are various sources such as Azure, GCP, AWS.', tokens=[51464, 400, 498, 291, 574, 412, 264, 1192, 11, 456, 366, 3683, 7139, 1270, 382, 11969, 11, 460, 20049, 11, 17650, 13, 51714]), TranscriptionSegment(id=45, avg_logprob=-0.45489823818206787, compression_ratio=1.625, end=213.0, no_speech_prob=8.479920506943017e-05, seek=20900, start=209.0, temperature=0.0, text=' So, if the MDC on the left captures information about security risks,', tokens=[50364, 407, 11, 498, 264, 22521, 34, 322, 264, 1411, 27986, 1589, 466, 3825, 10888, 11, 50564]), TranscriptionSegment(id=46, avg_logprob=-0.45489823818206787, compression_ratio=1.625, end=217.0, no_speech_prob=8.479920506943017e-05, seek=20900, start=213.0, temperature=0.0, text=' the Copilot on the right can ask more detailed questions,', tokens=[50564, 264, 11579, 31516, 322, 264, 558, 393, 1029, 544, 9942, 1651, 11, 50764]), TranscriptionSegment(id=47, avg_logprob=-0.45489823818206787, compression_ratio=1.625, end=220.0, no_speech_prob=8.479920506943017e-05, seek=20900, start=217.0, temperature=0.0, text=' analyze, and respond.', tokens=[50764, 12477, 11, 293, 4196, 13, 50914]), TranscriptionSegment(id=48, avg_logprob=-0.45489823818206787, compression_ratio=1.625, end=224.0, no_speech_prob=8.479920506943017e-05, seek=20900, start=220.0, temperature=0.0, text=' And as an example, I told you to summarize the contents on the left,', tokens=[50914, 400, 382, 364, 1365, 11, 286, 1907, 291, 281, 20858, 264, 15768, 322, 264, 1411, 11, 51114]), TranscriptionSegment(id=49, avg_logprob=-0.45489823818206787, compression_ratio=1.625, end=229.0, no_speech_prob=8.479920506943017e-05, seek=20900, start=224.0, temperature=0.0, text=' and the right tells you those contents and provides insights.', tokens=[51114, 293, 264, 558, 5112, 291, 729, 15768, 293, 6417, 14310, 13, 51364]), TranscriptionSegment(id=50, avg_logprob=-0.45489823818206787, compression_ratio=1.625, end=233.0, no_speech_prob=8.479920506943017e-05, seek=20900, start=229.0, temperature=0.0, text=' The second feature is Risk Remediation.', tokens=[51364, 440, 1150, 4111, 307, 45892, 4080, 292, 6642, 13, 51564]), TranscriptionSegment(id=51, avg_logprob=-0.45489823818206787, compression_ratio=1.625, end=235.0, no_speech_prob=8.479920506943017e-05, seek=20900, start=233.0, temperature=0.0, text=' It helps you respond to risks.', tokens=[51564, 467, 3665, 291, 4196, 281, 10888, 13, 51664]), TranscriptionSegment(id=52, avg_logprob=-0.4466911852359772, compression_ratio=1.7293232679367065, end=238.0, no_speech_prob=0.08860218524932861, seek=23500, start=235.0, temperature=0.0, text=' So, using the AI-integrated remediation function,', tokens=[50364, 407, 11, 1228, 264, 7318, 12, 31131, 770, 28718, 6642, 2445, 11, 50514]), TranscriptionSegment(id=53, avg_logprob=-0.4466911852359772, compression_ratio=1.7293232679367065, end=241.0, no_speech_prob=0.08860218524932861, seek=23500, start=238.0, temperature=0.0, text=' you can receive a warning, read it,', tokens=[50514, 291, 393, 4774, 257, 9164, 11, 1401, 309, 11, 50664]), TranscriptionSegment(id=54, avg_logprob=-0.4466911852359772, compression_ratio=1.7293232679367065, end=244.0, no_speech_prob=0.08860218524932861, seek=23500, start=241.0, temperature=0.0, text=' understand the content, and take the necessary action.', tokens=[50664, 1223, 264, 2701, 11, 293, 747, 264, 4818, 3069, 13, 50814]), TranscriptionSegment(id=55, avg_logprob=-0.4466911852359772, compression_ratio=1.7293232679367065, end=247.0, no_speech_prob=0.08860218524932861, seek=23500, start=244.0, temperature=0.0, text=' If you look at the right screen for a moment,', tokens=[50814, 759, 291, 574, 412, 264, 558, 2568, 337, 257, 1623, 11, 50964]), TranscriptionSegment(id=56, avg_logprob=-0.4466911852359772, compression_ratio=1.7293232679367065, end=250.0, no_speech_prob=0.08860218524932861, seek=23500, start=247.0, temperature=0.0, text=' you can see a summary and insight on the current situation on the previous screen.', tokens=[50964, 291, 393, 536, 257, 12691, 293, 11269, 322, 264, 2190, 2590, 322, 264, 3894, 2568, 13, 51114]), TranscriptionSegment(id=57, avg_logprob=-0.4466911852359772, compression_ratio=1.7293232679367065, end=256.0, no_speech_prob=0.08860218524932861, seek=23500, start=250.0, temperature=0.0, text=' This time, I told the Copilot to ask where the resources related to vulnerability are,', tokens=[51114, 639, 565, 11, 286, 1907, 264, 11579, 31516, 281, 1029, 689, 264, 3593, 4077, 281, 24210, 366, 11, 51414]), TranscriptionSegment(id=58, avg_logprob=-0.4466911852359772, compression_ratio=1.7293232679367065, end=260.0, no_speech_prob=0.08860218524932861, seek=23500, start=256.0, temperature=0.0, text=' and I asked him to focus on that a little more.', tokens=[51414, 293, 286, 2351, 796, 281, 1879, 322, 300, 257, 707, 544, 13, 51614]), TranscriptionSegment(id=59, avg_logprob=-0.4466911852359772, compression_ratio=1.7293232679367065, end=264.0, no_speech_prob=0.08860218524932861, seek=23500, start=260.0, temperature=0.0, text=' You can see that the Copilot is telling you about this.', tokens=[51614, 509, 393, 536, 300, 264, 11579, 31516, 307, 3585, 291, 466, 341, 13, 51814]), TranscriptionSegment(id=60, avg_logprob=-0.41832178831100464, compression_ratio=1.688596487045288, end=268.0, no_speech_prob=0.001410099328495562, seek=26400, start=264.0, temperature=0.0, text=' Lastly, there is the automated threat remediation function.', tokens=[50364, 18072, 11, 456, 307, 264, 18473, 4734, 28718, 6642, 2445, 13, 50564]), TranscriptionSegment(id=61, avg_logprob=-0.41832178831100464, compression_ratio=1.688596487045288, end=271.0, no_speech_prob=0.001410099328495562, seek=26400, start=268.0, temperature=0.0, text=' It uses the full request function created by the AI', tokens=[50564, 467, 4960, 264, 1577, 5308, 2445, 2942, 538, 264, 7318, 50714]), TranscriptionSegment(id=62, avg_logprob=-0.41832178831100464, compression_ratio=1.688596487045288, end=276.0, no_speech_prob=0.001410099328495562, seek=26400, start=271.0, temperature=0.0, text=' to correct code miscomplications on DevOps.', tokens=[50714, 281, 3006, 3089, 3346, 1112, 4770, 763, 322, 43051, 13, 50964]), TranscriptionSegment(id=63, avg_logprob=-0.41832178831100464, compression_ratio=1.688596487045288, end=278.0, no_speech_prob=0.001410099328495562, seek=26400, start=276.0, temperature=0.0, text=' If you look at the right on the left,', tokens=[50964, 759, 291, 574, 412, 264, 558, 322, 264, 1411, 11, 51064]), TranscriptionSegment(id=64, avg_logprob=-0.41832178831100464, compression_ratio=1.688596487045288, end=284.0, no_speech_prob=0.001410099328495562, seek=26400, start=278.0, temperature=0.0, text=' it asks if you will submit a full request to solve the problem on Azure DevOps.', tokens=[51064, 309, 8962, 498, 291, 486, 10315, 257, 1577, 5308, 281, 5039, 264, 1154, 322, 11969, 43051, 13, 51364]), TranscriptionSegment(id=65, avg_logprob=-0.41832178831100464, compression_ratio=1.688596487045288, end=288.0, no_speech_prob=0.001410099328495562, seek=26400, start=284.0, temperature=0.0, text=' So, if you submit this, the contents will be updated to Azure DevOps', tokens=[51364, 407, 11, 498, 291, 10315, 341, 11, 264, 15768, 486, 312, 10588, 281, 11969, 43051, 51564]), TranscriptionSegment(id=66, avg_logprob=-0.41832178831100464, compression_ratio=1.688596487045288, end=291.0, no_speech_prob=0.001410099328495562, seek=26400, start=288.0, temperature=0.0, text=' and you can correct the wrong explanation.', tokens=[51564, 293, 291, 393, 3006, 264, 2085, 10835, 13, 51714]), TranscriptionSegment(id=67, avg_logprob=-0.374963641166687, compression_ratio=1.6623376607894897, end=296.0, no_speech_prob=0.0016993407625705004, seek=29100, start=292.0, temperature=0.0, text=' To sum up, you can quickly understand the current situation through MDC and Copilot,', tokens=[50414, 1407, 2408, 493, 11, 291, 393, 2661, 1223, 264, 2190, 2590, 807, 22521, 34, 293, 11579, 31516, 11, 50614]), TranscriptionSegment(id=68, avg_logprob=-0.374963641166687, compression_ratio=1.6623376607894897, end=300.0, no_speech_prob=0.0016993407625705004, seek=29100, start=296.0, temperature=0.0, text=' and you can get a guide and automated solution to solve the problem.', tokens=[50614, 293, 291, 393, 483, 257, 5934, 293, 18473, 3827, 281, 5039, 264, 1154, 13, 50814]), TranscriptionSegment(id=69, avg_logprob=-0.374963641166687, compression_ratio=1.6623376607894897, end=305.0, no_speech_prob=0.0016993407625705004, seek=29100, start=300.0, temperature=0.0, text=' Through this, you can operate security more smartly than before.', tokens=[50814, 8927, 341, 11, 291, 393, 9651, 3825, 544, 4069, 356, 813, 949, 13, 51064]), TranscriptionSegment(id=70, avg_logprob=-0.374963641166687, compression_ratio=1.6623376607894897, end=309.0, no_speech_prob=0.0016993407625705004, seek=29100, start=305.0, temperature=0.0, text=' This is the effect you can get by linking', tokens=[51064, 639, 307, 264, 1802, 291, 393, 483, 538, 25775, 51264]), TranscriptionSegment(id=71, avg_logprob=-0.374963641166687, compression_ratio=1.6623376607894897, end=312.0, no_speech_prob=0.0016993407625705004, seek=29100, start=309.0, temperature=0.0, text=' Copilot for Security, an AI solution,', tokens=[51264, 11579, 31516, 337, 11164, 11, 364, 7318, 3827, 11, 51414]), TranscriptionSegment(id=72, avg_logprob=-0.374963641166687, compression_ratio=1.6623376607894897, end=315.0, no_speech_prob=0.0016993407625705004, seek=29100, start=312.0, temperature=0.0, text=' and Microsoft Vendor for Cloud for cloud security.', tokens=[51414, 293, 8116, 691, 521, 284, 337, 8061, 337, 4588, 3825, 13, 51564]), TranscriptionSegment(id=73, avg_logprob=-0.374963641166687, compression_ratio=1.6623376607894897, end=317.0, no_speech_prob=0.0016993407625705004, seek=29100, start=315.0, temperature=0.0, text=\" That's it for today's explanation.\", tokens=[51564, 663, 311, 309, 337, 965, 311, 10835, 13, 51664]), TranscriptionSegment(id=74, avg_logprob=-0.393223375082016, compression_ratio=1.0256410837173462, end=321.0, no_speech_prob=0.2861874997615814, seek=31700, start=317.0, temperature=0.0, text=' Please continue to pay attention to Microsoft security.', tokens=[50364, 2555, 2354, 281, 1689, 3202, 281, 8116, 3825, 13, 50564]), TranscriptionSegment(id=75, avg_logprob=-0.393223375082016, compression_ratio=1.0256410837173462, end=323.0, no_speech_prob=0.2861874997615814, seek=31700, start=321.0, temperature=0.0, text=' Thank you for listening.', tokens=[50564, 1044, 291, 337, 4764, 13, 50664])], words=None, task='translate')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_whisper(AUDIO_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "def call_gpt(system_prompt, user_prompt, max_tokens = 500):\n",
    "    \"\"\"\n",
    "    Function to generate text using GPT-4o chat completion.\n",
    "    \n",
    "    Args:\n",
    "        system_prompt (str): System prompt.\n",
    "        user_prompt (str): User prompt.\n",
    "        max_tokens (int): Maximum number of tokens to generate, default is 500.\n",
    "    Returns:\n",
    "        result (str): Generated text.\n",
    "    \n",
    "    * Uses Azure AI Services OpenAI\n",
    "    \"\"\"\n",
    "        \n",
    "    aoai_client_gpt = AzureOpenAI(\n",
    "        api_key = os.getenv(\"AOAI_API_KEY\"),  \n",
    "        api_version = \"2024-02-01\",\n",
    "        azure_endpoint = os.getenv(\"AOAI_ENDPOINT_GPT\")\n",
    "    )\n",
    "\n",
    "    gpt_input = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    response = aoai_client_gpt.chat.completions.create(\n",
    "        messages = gpt_input,            \n",
    "        model = \"gpt-4o\",\n",
    "        max_tokens = max_tokens\n",
    "    )\n",
    "\n",
    "    result = response.choices[0].message.content\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'맞아요! 하지만 정확한 날씨는 현재 위치와 상황에 따라 다를 수 있어요. 지역 날씨를 확인해 보셨나요? 그렇지 않더라도 날씨가 안 좋다면 실내에서 좋은 시간을 보내는 것도 좋은 방법일 거예요! 😊'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt(\"한국어로 대답하세요.\", \"오늘 날씨 좋지 않아?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test STT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cognitiveservices-speech in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (1.42.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-cognitiveservices-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import time\n",
    "\n",
    "def call_stt(audio_file_path):\n",
    "    \"\"\"\n",
    "    Function to convert audio to text using Azure Speech SDK.\n",
    "    \n",
    "    Args:\n",
    "        audio_file_path (str): Path to the audio file, including the file name and extension. e.g., \"testfiles/testaudio.mp3\"\n",
    "    Returns:\n",
    "        recognized_text (str): STT result text.\n",
    "        recognized_chunks (list): List of recognized text chunks.\n",
    "\n",
    "    * Uses Azure AI Services Speech SDK\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configure speech recognizer\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=AI_SERVICES_SPEECH_KEY, region=AI_SERVICES_SPEECH_REGION)\n",
    "    speech_config.speech_recognition_language = \"ko-KR\"\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=audio_file_path)\n",
    "\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    # For saving the recognized text\n",
    "    done = False\n",
    "    recognized_text = \"\"\n",
    "    recognized_chunks = []\n",
    "\n",
    "    def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "        \"\"\"Callback function called upon session exit\"\"\"\n",
    "        nonlocal done\n",
    "        print(\"Session stopped. Checking if end of audio...\")\n",
    "\n",
    "        # End STT if end of audio\n",
    "        if evt.reason == speechsdk.ResultReason.NoMatch:\n",
    "            print(\"End of audio detected. Stopping STT.\")\n",
    "            done = True\n",
    "        else:\n",
    "            print(\"Restarting STT...\")\n",
    "            speech_recognizer.start_continuous_recognition()\n",
    "\n",
    "    def recognized(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "        \"\"\"Callback function called upon speech recognition\"\"\"\n",
    "        nonlocal recognized_text, recognized_chunks\n",
    "\n",
    "        # Prevent redundant calls\n",
    "        if evt.result.text and (not recognized_chunks or evt.result.text != recognized_chunks[-1]):\n",
    "            recognized_chunks.append(evt.result.text)\n",
    "            recognized_text += evt.result.text + \" \"\n",
    "            print(f\"Recognized: {evt.result.text}\")\n",
    "\n",
    "    # Disconnect before reconnecting event (Prevent redundant calls)\n",
    "    speech_recognizer.recognized.disconnect_all()\n",
    "    speech_recognizer.session_stopped.disconnect_all()\n",
    "    speech_recognizer.canceled.disconnect_all()\n",
    "\n",
    "    speech_recognizer.recognized.connect(recognized)\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "    # Speech recognized, start transcription\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "\n",
    "    # Delay before stopping session\n",
    "    timeout = time.time() + 300  # 300seconds limit\n",
    "    while not done and time.time() < timeout:\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # Force stop\n",
    "    speech_recognizer.stop_continuous_recognition()\n",
    "\n",
    "    print(f\"Final Recognized Text: {recognized_text}\")\n",
    "\n",
    "    return recognized_text, recognized_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized: 안녕하세요. 저는 한국 마이크로소프트에서 보안 부분에 대한 전략 수립과 그다음에 사업 운영을 담당하고 있는 박상준이라고 합니다. 오늘 저는 빌드 여러 보안 세션 중에서 어 마이크로소프트 코파일 포스케이트를 통한 멀티 클라우드 대보우스를 지원하는 방법이 어떤 것이 있는지 어 설명을 드리고자 합니다.\n",
      "Recognized: 먼저 세션 시작하기 전에 인제 코팔로 퍼시기 때문에 설명을 좀 먼저 드릴 필요가 있는데요. 코파일러 포시큐티에 대해서 모르시는 분이 있을 수 있어서 먼저 설명을 간단하게 드리면 전 세계 최초 그리고 유일한 GPT 포 기반의 생성형 AI 기반 보안 솔루션입니다. 저희가 1년 전쯤에 프리뷰를 발표하였고요. 올해 사월에 어 정식 지회가 되었습니다. 그 AI 를 통해서 고객의 사이버 보안 수준을 혁신적으로 어 올릴 수 있는 풀루션이 되겠습니다.\n",
      "Recognized: 이 기반에는 어마어마한 데이터를 기반으로 학습되어 있는데요. 약 65조 개 보안 시그널을 통해서 코파일러스 퍼시트를 학습시켰고요. 이를 통해서 머신 스피드하고 스케일로 저희가 지원해 드리는데 이 말은 무슨 말이냐면 굉장히 빠른 속도와 스케일을 통해서 고객을 도와드린다는 얘기고요. 어 이는 마치 우리 옆에 음 초급이나 중급 보안 엔진을 두고 이분들한테 간단한 내용들을 학습시키고 저희 업무를 도움을 주게 하는 형태와 같습니다.\n",
      "Recognized: 어 일반적인 AI 와 달리 이거는 이제 기업 전용으로 제공이 되고요. 또 고객의 데이터를 AI 학습용으로 활용하지 않습니다. 그래서 고객의 데이터에 대한 유출 걱정 없이 어 AI 를 활용할 수 있습니다. 아울러 이번 빌드에서는 코팔프 시큐티에 연동되는 제품이 더 확대되어서 저희가 이제 MDC 라고 부르는데요. 어 디펜더쿠 클라우드까지 확대가 되었습니다. 요번에는 아직 퍼블릭 필뷰 상태인데요. 이에 대한 자세한 설명을 드리도록 하겠습니다.\n",
      "Recognized: 먼저 동작 방식에 대한 부분을 말씀드리도록 하겠습니다. 어 제목에서 보시면 머신 스피드하고 스케일인데요. 말씀드렸다시피 매우 빠른 속도와 확장성을 갖고 있고요. 어 일반적으로 보안 업무자가 몇 시간 또는 며칠 걸리던 작업들을 어 몇 분 이내 어 완료할 수 있는 것이 되겠고요. 이러한 역량들을 MDC 까지 어 확대했다는 얘기가 되겠습니다. 왼쪽을 보시면 세 가지 베리핏이 있는데요. 먼저 첫 번째는.\n",
      "Recognized: 복잡한 것을 단순화 시킬 수 있습니다. 실제로는 보안 시그널들이 엄청나게 많은데 이런 노이즈를 줄이고 자연어를 이용해서 쉽게 분류하고 대응할 수 있습니다. 어 2번째 특징은 어 놓치는 거 없이 탐지하는 것입니다. 코파일럿과 MDC 를 같이 사용하면 보안 관리자들은 노이즈를 필터링함으로써 놓치는 것이 없이 모든 것을 잘 포착하고 빠르게 수정해서 복잡성을 간소화시킬 수 있습니다. 마지막.\n",
      "Recognized: 으로는 빠르게 대응하는 것인데요. 어 소스 코드 상에서 문제가 있거나 그런 거를 해결하기 위해서 AI 가 해결한 액션을 제공해 드리고 있습니다. 이런 것들을 통해서 문제를 팩하게 해결할 수 있습니다. 이에 대한 각각 대한 설명을 다음번에 드리도록 하겠습니다. 먼저 1번째 기능인데요, 위험 사항을 알아보는 것입니다. 고객사 클라우드 환경에서 어떤 부분이 중요하고 위험한지 를 빠르게 알려줄 수 있는 건데요. 먼저 오른쪽 화면을 보시면 왼쪽이 이제 MDC 화면이고 오른쪽이 임베디드에 있는 코.\n",
      "Recognized: 화면입니다. 그리고 상단에 보시면 에저 주시 PAWS 뭐 이런 여러 가지 솔루션들이 있습니다. 그래서 왼쪽에서 MDC 가 보안 위험 상황에 대해서 정보를 캡처하면 오른쪽에 코파일럿을 갖고 어 좀 더 세부적인 내용을 물어본다던가 분석한다든가 대응할 수 있게 되겠습니다. 그리고 현재 예시로는 어 왼쪽에 있는 내용들을 좀 써머리 해라고 했더니 오른쪽에서 예, 그런 내용들을 알려주고 어 이에 대한 인사이트를 어 제공해 주고 있습니다.\n",
      "Recognized: 2번째 기능은 리스크 레미데이션인데요. 위험에 대해서 대응해 주는 것을 도와주는 겁니다. 그래서 AI 통합돼 있는 그 레미제이션 기능을 활용해서 권고 사항을 받을 수 있고 이걸 읽어보시고 내용을 이해해서 어 필요한 액션을 취할 수 있습니다. 오른쪽 화면을 잠깐 보시면 어? 이 점 화면에서는 현재 상황에 대한 써머리하고 인사이트 볼 수 있었는데요. 이번에는 코파일러한테 어떠한 위험성이 있는 벌러 비티에 관련된 리소스가 어디에 있는지를 물어보라고 했는데.\n",
      "Recognized: 그거에 대해서 조금 더 포커스해서 알려달라라고 명령을 하였구요. 어? 이에 대해서 코파일럿이 알려주고 있음을 확인할 수 있습니다. 마지막으로는 자동화되어 있는 그 위협 레미제이션 기능인데요. 어 AI 생성된 풀 리퀘스트 기능을 이용하여 그 대부업 수상에서 코드 위스 컴필레이션 같은 것들을 수정하게 하는 것입니다. 그 왼쪽에 오른쪽을 보시면 에저 대부업 상에 문제가 있는 부분을 해결하기 위해서 풀 리퀘스트를 써밋 하겠냐고 물어보게 됩니다. 그래서 이걸 써밋하면 해당 내용들이 어 예전.\n",
      "Recognized: 업데이트가 되고 잘못된 설명을 추정할 수 있습니다.\n",
      "Recognized: 그 정리해 보면 MDC 하고 코파를 통해서 현재의 상태를 획하게 알 수 있고 어 문제 해결을 위하여 가이드와 자동화된 해결책을 얻을 수 있고요. 어 이를 통해서 이전에 비해서 좀 더 스마트하게 보안 운영을 하실 수 있습니다. 이것이 AI 설루션인 코파일럿 포시큐티하고 클라우드 보안을 위한 마이크로소프트 벤더 포 클라우드의 연동을 통해서 얻을 수 있는 효과입니다.\n",
      "Recognized: 오늘 설명은 여기까지구요. 앞으로도 마이크로소프트 보안에 대해서 지속적으로 관심을 부탁드리겠습니다. 경청해 주셔서 감사합니다.\n",
      "Session stopped. Checking if end of audio...\n",
      "Session stopped. Checking if end of audio...\n",
      "Final Recognized Text: 안녕하세요. 저는 한국 마이크로소프트에서 보안 부분에 대한 전략 수립과 그다음에 사업 운영을 담당하고 있는 박상준이라고 합니다. 오늘 저는 빌드 여러 보안 세션 중에서 어 마이크로소프트 코파일 포스케이트를 통한 멀티 클라우드 대보우스를 지원하는 방법이 어떤 것이 있는지 어 설명을 드리고자 합니다. 먼저 세션 시작하기 전에 인제 코팔로 퍼시기 때문에 설명을 좀 먼저 드릴 필요가 있는데요. 코파일러 포시큐티에 대해서 모르시는 분이 있을 수 있어서 먼저 설명을 간단하게 드리면 전 세계 최초 그리고 유일한 GPT 포 기반의 생성형 AI 기반 보안 솔루션입니다. 저희가 1년 전쯤에 프리뷰를 발표하였고요. 올해 사월에 어 정식 지회가 되었습니다. 그 AI 를 통해서 고객의 사이버 보안 수준을 혁신적으로 어 올릴 수 있는 풀루션이 되겠습니다. 이 기반에는 어마어마한 데이터를 기반으로 학습되어 있는데요. 약 65조 개 보안 시그널을 통해서 코파일러스 퍼시트를 학습시켰고요. 이를 통해서 머신 스피드하고 스케일로 저희가 지원해 드리는데 이 말은 무슨 말이냐면 굉장히 빠른 속도와 스케일을 통해서 고객을 도와드린다는 얘기고요. 어 이는 마치 우리 옆에 음 초급이나 중급 보안 엔진을 두고 이분들한테 간단한 내용들을 학습시키고 저희 업무를 도움을 주게 하는 형태와 같습니다. 어 일반적인 AI 와 달리 이거는 이제 기업 전용으로 제공이 되고요. 또 고객의 데이터를 AI 학습용으로 활용하지 않습니다. 그래서 고객의 데이터에 대한 유출 걱정 없이 어 AI 를 활용할 수 있습니다. 아울러 이번 빌드에서는 코팔프 시큐티에 연동되는 제품이 더 확대되어서 저희가 이제 MDC 라고 부르는데요. 어 디펜더쿠 클라우드까지 확대가 되었습니다. 요번에는 아직 퍼블릭 필뷰 상태인데요. 이에 대한 자세한 설명을 드리도록 하겠습니다. 먼저 동작 방식에 대한 부분을 말씀드리도록 하겠습니다. 어 제목에서 보시면 머신 스피드하고 스케일인데요. 말씀드렸다시피 매우 빠른 속도와 확장성을 갖고 있고요. 어 일반적으로 보안 업무자가 몇 시간 또는 며칠 걸리던 작업들을 어 몇 분 이내 어 완료할 수 있는 것이 되겠고요. 이러한 역량들을 MDC 까지 어 확대했다는 얘기가 되겠습니다. 왼쪽을 보시면 세 가지 베리핏이 있는데요. 먼저 첫 번째는. 복잡한 것을 단순화 시킬 수 있습니다. 실제로는 보안 시그널들이 엄청나게 많은데 이런 노이즈를 줄이고 자연어를 이용해서 쉽게 분류하고 대응할 수 있습니다. 어 2번째 특징은 어 놓치는 거 없이 탐지하는 것입니다. 코파일럿과 MDC 를 같이 사용하면 보안 관리자들은 노이즈를 필터링함으로써 놓치는 것이 없이 모든 것을 잘 포착하고 빠르게 수정해서 복잡성을 간소화시킬 수 있습니다. 마지막. 으로는 빠르게 대응하는 것인데요. 어 소스 코드 상에서 문제가 있거나 그런 거를 해결하기 위해서 AI 가 해결한 액션을 제공해 드리고 있습니다. 이런 것들을 통해서 문제를 팩하게 해결할 수 있습니다. 이에 대한 각각 대한 설명을 다음번에 드리도록 하겠습니다. 먼저 1번째 기능인데요, 위험 사항을 알아보는 것입니다. 고객사 클라우드 환경에서 어떤 부분이 중요하고 위험한지 를 빠르게 알려줄 수 있는 건데요. 먼저 오른쪽 화면을 보시면 왼쪽이 이제 MDC 화면이고 오른쪽이 임베디드에 있는 코. 화면입니다. 그리고 상단에 보시면 에저 주시 PAWS 뭐 이런 여러 가지 솔루션들이 있습니다. 그래서 왼쪽에서 MDC 가 보안 위험 상황에 대해서 정보를 캡처하면 오른쪽에 코파일럿을 갖고 어 좀 더 세부적인 내용을 물어본다던가 분석한다든가 대응할 수 있게 되겠습니다. 그리고 현재 예시로는 어 왼쪽에 있는 내용들을 좀 써머리 해라고 했더니 오른쪽에서 예, 그런 내용들을 알려주고 어 이에 대한 인사이트를 어 제공해 주고 있습니다. 2번째 기능은 리스크 레미데이션인데요. 위험에 대해서 대응해 주는 것을 도와주는 겁니다. 그래서 AI 통합돼 있는 그 레미제이션 기능을 활용해서 권고 사항을 받을 수 있고 이걸 읽어보시고 내용을 이해해서 어 필요한 액션을 취할 수 있습니다. 오른쪽 화면을 잠깐 보시면 어? 이 점 화면에서는 현재 상황에 대한 써머리하고 인사이트 볼 수 있었는데요. 이번에는 코파일러한테 어떠한 위험성이 있는 벌러 비티에 관련된 리소스가 어디에 있는지를 물어보라고 했는데. 그거에 대해서 조금 더 포커스해서 알려달라라고 명령을 하였구요. 어? 이에 대해서 코파일럿이 알려주고 있음을 확인할 수 있습니다. 마지막으로는 자동화되어 있는 그 위협 레미제이션 기능인데요. 어 AI 생성된 풀 리퀘스트 기능을 이용하여 그 대부업 수상에서 코드 위스 컴필레이션 같은 것들을 수정하게 하는 것입니다. 그 왼쪽에 오른쪽을 보시면 에저 대부업 상에 문제가 있는 부분을 해결하기 위해서 풀 리퀘스트를 써밋 하겠냐고 물어보게 됩니다. 그래서 이걸 써밋하면 해당 내용들이 어 예전. 업데이트가 되고 잘못된 설명을 추정할 수 있습니다. 그 정리해 보면 MDC 하고 코파를 통해서 현재의 상태를 획하게 알 수 있고 어 문제 해결을 위하여 가이드와 자동화된 해결책을 얻을 수 있고요. 어 이를 통해서 이전에 비해서 좀 더 스마트하게 보안 운영을 하실 수 있습니다. 이것이 AI 설루션인 코파일럿 포시큐티하고 클라우드 보안을 위한 마이크로소프트 벤더 포 클라우드의 연동을 통해서 얻을 수 있는 효과입니다. 오늘 설명은 여기까지구요. 앞으로도 마이크로소프트 보안에 대해서 지속적으로 관심을 부탁드리겠습니다. 경청해 주셔서 감사합니다. \n"
     ]
    }
   ],
   "source": [
    "recognized_text, recognized_chunks = call_stt(\"AudioDummy_MicrosoftBuild2024_CopilotforSecurity.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요. 저는 한국 마이크로소프트에서 보안 부분에 대한 전략 수립과 그다음에 사업 운영을 담당하고 있는 박상준이라고 합니다. 오늘 저는 빌드 여러 보안 세션 중에서 어 마이크로소프트 코파일 포스케이트를 통한 멀티 클라우드 대보우스를 지원하는 방법이 어떤 것이 있는지 어 설명을 드리고자 합니다. 먼저 세션 시작하기 전에 인제 코팔로 퍼시기 때문에 설명을 좀 먼저 드릴 필요가 있는데요. 코파일러 포시큐티에 대해서 모르시는 분이 있을 수 있어서 먼저 설명을 간단하게 드리면 전 세계 최초 그리고 유일한 GPT 포 기반의 생성형 AI 기반 보안 솔루션입니다. 저희가 1년 전쯤에 프리뷰를 발표하였고요. 올해 사월에 어 정식 지회가 되었습니다. 그 AI 를 통해서 고객의 사이버 보안 수준을 혁신적으로 어 올릴 수 있는 풀루션이 되겠습니다. 이 기반에는 어마어마한 데이터를 기반으로 학습되어 있는데요. 약 65조 개 보안 시그널을 통해서 코파일러스 퍼시트를 학습시켰고요. 이를 통해서 머신 스피드하고 스케일로 저희가 지원해 드리는데 이 말은 무슨 말이냐면 굉장히 빠른 속도와 스케일을 통해서 고객을 도와드린다는 얘기고요. 어 이는 마치 우리 옆에 음 초급이나 중급 보안 엔진을 두고 이분들한테 간단한 내용들을 학습시키고 저희 업무를 도움을 주게 하는 형태와 같습니다. 어 일반적인 AI 와 달리 이거는 이제 기업 전용으로 제공이 되고요. 또 고객의 데이터를 AI 학습용으로 활용하지 않습니다. 그래서 고객의 데이터에 대한 유출 걱정 없이 어 AI 를 활용할 수 있습니다. 아울러 이번 빌드에서는 코팔프 시큐티에 연동되는 제품이 더 확대되어서 저희가 이제 MDC 라고 부르는데요. 어 디펜더쿠 클라우드까지 확대가 되었습니다. 요번에는 아직 퍼블릭 필뷰 상태인데요. 이에 대한 자세한 설명을 드리도록 하겠습니다. 먼저 동작 방식에 대한 부분을 말씀드리도록 하겠습니다. 어 제목에서 보시면 머신 스피드하고 스케일인데요. 말씀드렸다시피 매우 빠른 속도와 확장성을 갖고 있고요. 어 일반적으로 보안 업무자가 몇 시간 또는 며칠 걸리던 작업들을 어 몇 분 이내 어 완료할 수 있는 것이 되겠고요. 이러한 역량들을 MDC 까지 어 확대했다는 얘기가 되겠습니다. 왼쪽을 보시면 세 가지 베리핏이 있는데요. 먼저 첫 번째는. 복잡한 것을 단순화 시킬 수 있습니다. 실제로는 보안 시그널들이 엄청나게 많은데 이런 노이즈를 줄이고 자연어를 이용해서 쉽게 분류하고 대응할 수 있습니다. 어 2번째 특징은 어 놓치는 거 없이 탐지하는 것입니다. 코파일럿과 MDC 를 같이 사용하면 보안 관리자들은 노이즈를 필터링함으로써 놓치는 것이 없이 모든 것을 잘 포착하고 빠르게 수정해서 복잡성을 간소화시킬 수 있습니다. 마지막. 으로는 빠르게 대응하는 것인데요. 어 소스 코드 상에서 문제가 있거나 그런 거를 해결하기 위해서 AI 가 해결한 액션을 제공해 드리고 있습니다. 이런 것들을 통해서 문제를 팩하게 해결할 수 있습니다. 이에 대한 각각 대한 설명을 다음번에 드리도록 하겠습니다. 먼저 1번째 기능인데요, 위험 사항을 알아보는 것입니다. 고객사 클라우드 환경에서 어떤 부분이 중요하고 위험한지 를 빠르게 알려줄 수 있는 건데요. 먼저 오른쪽 화면을 보시면 왼쪽이 이제 MDC 화면이고 오른쪽이 임베디드에 있는 코. 화면입니다. 그리고 상단에 보시면 에저 주시 PAWS 뭐 이런 여러 가지 솔루션들이 있습니다. 그래서 왼쪽에서 MDC 가 보안 위험 상황에 대해서 정보를 캡처하면 오른쪽에 코파일럿을 갖고 어 좀 더 세부적인 내용을 물어본다던가 분석한다든가 대응할 수 있게 되겠습니다. 그리고 현재 예시로는 어 왼쪽에 있는 내용들을 좀 써머리 해라고 했더니 오른쪽에서 예, 그런 내용들을 알려주고 어 이에 대한 인사이트를 어 제공해 주고 있습니다. 2번째 기능은 리스크 레미데이션인데요. 위험에 대해서 대응해 주는 것을 도와주는 겁니다. 그래서 AI 통합돼 있는 그 레미제이션 기능을 활용해서 권고 사항을 받을 수 있고 이걸 읽어보시고 내용을 이해해서 어 필요한 액션을 취할 수 있습니다. 오른쪽 화면을 잠깐 보시면 어? 이 점 화면에서는 현재 상황에 대한 써머리하고 인사이트 볼 수 있었는데요. 이번에는 코파일러한테 어떠한 위험성이 있는 벌러 비티에 관련된 리소스가 어디에 있는지를 물어보라고 했는데. 그거에 대해서 조금 더 포커스해서 알려달라라고 명령을 하였구요. 어? 이에 대해서 코파일럿이 알려주고 있음을 확인할 수 있습니다. 마지막으로는 자동화되어 있는 그 위협 레미제이션 기능인데요. 어 AI 생성된 풀 리퀘스트 기능을 이용하여 그 대부업 수상에서 코드 위스 컴필레이션 같은 것들을 수정하게 하는 것입니다. 그 왼쪽에 오른쪽을 보시면 에저 대부업 상에 문제가 있는 부분을 해결하기 위해서 풀 리퀘스트를 써밋 하겠냐고 물어보게 됩니다. 그래서 이걸 써밋하면 해당 내용들이 어 예전. 업데이트가 되고 잘못된 설명을 추정할 수 있습니다. 그 정리해 보면 MDC 하고 코파를 통해서 현재의 상태를 획하게 알 수 있고 어 문제 해결을 위하여 가이드와 자동화된 해결책을 얻을 수 있고요. 어 이를 통해서 이전에 비해서 좀 더 스마트하게 보안 운영을 하실 수 있습니다. 이것이 AI 설루션인 코파일럿 포시큐티하고 클라우드 보안을 위한 마이크로소프트 벤더 포 클라우드의 연동을 통해서 얻을 수 있는 효과입니다. 오늘 설명은 여기까지구요. 앞으로도 마이크로소프트 보안에 대해서 지속적으로 관심을 부탁드리겠습니다. 경청해 주셔서 감사합니다. '"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['안녕하세요. 저는 한국 마이크로소프트에서 보안 부분에 대한 전략 수립과 그다음에 사업 운영을 담당하고 있는 박상준이라고 합니다. 오늘 저는 빌드 여러 보안 세션 중에서 어 마이크로소프트 코파일 포스케이트를 통한 멀티 클라우드 대보우스를 지원하는 방법이 어떤 것이 있는지 어 설명을 드리고자 합니다.',\n",
       " '먼저 세션 시작하기 전에 인제 코팔로 퍼시기 때문에 설명을 좀 먼저 드릴 필요가 있는데요. 코파일러 포시큐티에 대해서 모르시는 분이 있을 수 있어서 먼저 설명을 간단하게 드리면 전 세계 최초 그리고 유일한 GPT 포 기반의 생성형 AI 기반 보안 솔루션입니다. 저희가 1년 전쯤에 프리뷰를 발표하였고요. 올해 사월에 어 정식 지회가 되었습니다. 그 AI 를 통해서 고객의 사이버 보안 수준을 혁신적으로 어 올릴 수 있는 풀루션이 되겠습니다.',\n",
       " '이 기반에는 어마어마한 데이터를 기반으로 학습되어 있는데요. 약 65조 개 보안 시그널을 통해서 코파일러스 퍼시트를 학습시켰고요. 이를 통해서 머신 스피드하고 스케일로 저희가 지원해 드리는데 이 말은 무슨 말이냐면 굉장히 빠른 속도와 스케일을 통해서 고객을 도와드린다는 얘기고요. 어 이는 마치 우리 옆에 음 초급이나 중급 보안 엔진을 두고 이분들한테 간단한 내용들을 학습시키고 저희 업무를 도움을 주게 하는 형태와 같습니다.',\n",
       " '어 일반적인 AI 와 달리 이거는 이제 기업 전용으로 제공이 되고요. 또 고객의 데이터를 AI 학습용으로 활용하지 않습니다. 그래서 고객의 데이터에 대한 유출 걱정 없이 어 AI 를 활용할 수 있습니다. 아울러 이번 빌드에서는 코팔프 시큐티에 연동되는 제품이 더 확대되어서 저희가 이제 MDC 라고 부르는데요. 어 디펜더쿠 클라우드까지 확대가 되었습니다. 요번에는 아직 퍼블릭 필뷰 상태인데요. 이에 대한 자세한 설명을 드리도록 하겠습니다.',\n",
       " '먼저 동작 방식에 대한 부분을 말씀드리도록 하겠습니다. 어 제목에서 보시면 머신 스피드하고 스케일인데요. 말씀드렸다시피 매우 빠른 속도와 확장성을 갖고 있고요. 어 일반적으로 보안 업무자가 몇 시간 또는 며칠 걸리던 작업들을 어 몇 분 이내 어 완료할 수 있는 것이 되겠고요. 이러한 역량들을 MDC 까지 어 확대했다는 얘기가 되겠습니다. 왼쪽을 보시면 세 가지 베리핏이 있는데요. 먼저 첫 번째는.',\n",
       " '복잡한 것을 단순화 시킬 수 있습니다. 실제로는 보안 시그널들이 엄청나게 많은데 이런 노이즈를 줄이고 자연어를 이용해서 쉽게 분류하고 대응할 수 있습니다. 어 2번째 특징은 어 놓치는 거 없이 탐지하는 것입니다. 코파일럿과 MDC 를 같이 사용하면 보안 관리자들은 노이즈를 필터링함으로써 놓치는 것이 없이 모든 것을 잘 포착하고 빠르게 수정해서 복잡성을 간소화시킬 수 있습니다. 마지막.',\n",
       " '으로는 빠르게 대응하는 것인데요. 어 소스 코드 상에서 문제가 있거나 그런 거를 해결하기 위해서 AI 가 해결한 액션을 제공해 드리고 있습니다. 이런 것들을 통해서 문제를 팩하게 해결할 수 있습니다. 이에 대한 각각 대한 설명을 다음번에 드리도록 하겠습니다. 먼저 1번째 기능인데요, 위험 사항을 알아보는 것입니다. 고객사 클라우드 환경에서 어떤 부분이 중요하고 위험한지 를 빠르게 알려줄 수 있는 건데요. 먼저 오른쪽 화면을 보시면 왼쪽이 이제 MDC 화면이고 오른쪽이 임베디드에 있는 코.',\n",
       " '화면입니다. 그리고 상단에 보시면 에저 주시 PAWS 뭐 이런 여러 가지 솔루션들이 있습니다. 그래서 왼쪽에서 MDC 가 보안 위험 상황에 대해서 정보를 캡처하면 오른쪽에 코파일럿을 갖고 어 좀 더 세부적인 내용을 물어본다던가 분석한다든가 대응할 수 있게 되겠습니다. 그리고 현재 예시로는 어 왼쪽에 있는 내용들을 좀 써머리 해라고 했더니 오른쪽에서 예, 그런 내용들을 알려주고 어 이에 대한 인사이트를 어 제공해 주고 있습니다.',\n",
       " '2번째 기능은 리스크 레미데이션인데요. 위험에 대해서 대응해 주는 것을 도와주는 겁니다. 그래서 AI 통합돼 있는 그 레미제이션 기능을 활용해서 권고 사항을 받을 수 있고 이걸 읽어보시고 내용을 이해해서 어 필요한 액션을 취할 수 있습니다. 오른쪽 화면을 잠깐 보시면 어? 이 점 화면에서는 현재 상황에 대한 써머리하고 인사이트 볼 수 있었는데요. 이번에는 코파일러한테 어떠한 위험성이 있는 벌러 비티에 관련된 리소스가 어디에 있는지를 물어보라고 했는데.',\n",
       " '그거에 대해서 조금 더 포커스해서 알려달라라고 명령을 하였구요. 어? 이에 대해서 코파일럿이 알려주고 있음을 확인할 수 있습니다. 마지막으로는 자동화되어 있는 그 위협 레미제이션 기능인데요. 어 AI 생성된 풀 리퀘스트 기능을 이용하여 그 대부업 수상에서 코드 위스 컴필레이션 같은 것들을 수정하게 하는 것입니다. 그 왼쪽에 오른쪽을 보시면 에저 대부업 상에 문제가 있는 부분을 해결하기 위해서 풀 리퀘스트를 써밋 하겠냐고 물어보게 됩니다. 그래서 이걸 써밋하면 해당 내용들이 어 예전.',\n",
       " '업데이트가 되고 잘못된 설명을 추정할 수 있습니다.',\n",
       " '그 정리해 보면 MDC 하고 코파를 통해서 현재의 상태를 획하게 알 수 있고 어 문제 해결을 위하여 가이드와 자동화된 해결책을 얻을 수 있고요. 어 이를 통해서 이전에 비해서 좀 더 스마트하게 보안 운영을 하실 수 있습니다. 이것이 AI 설루션인 코파일럿 포시큐티하고 클라우드 보안을 위한 마이크로소프트 벤더 포 클라우드의 연동을 통해서 얻을 수 있는 효과입니다.',\n",
       " '오늘 설명은 여기까지구요. 앞으로도 마이크로소프트 보안에 대해서 지속적으로 관심을 부탁드리겠습니다. 경청해 주셔서 감사합니다.']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognized_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp313-cp313-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Using cached regex-2024.11.6-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
      "Downloading tiktoken-0.9.0-cp313-cp313-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.7 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 524.3/894.7 kB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 894.7/894.7 kB 3.4 MB/s eta 0:00:00\n",
      "Using cached regex-2024.11.6-cp313-cp313-win_amd64.whl (273 kB)\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2024.11.6 tiktoken-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "\n",
    "\n",
    "def call_gpt_for_refinement(stt_chunk):\n",
    "    pitch_purpose = \"Azure Machine Learning\"\n",
    "    max_tokens = 1000\n",
    "\n",
    "    system_prompt = \"STT 퀄리티 개선을 위해 잘못 변환된 단어만을 수정해줘.\"\n",
    "    user_base_prompt = f\"{pitch_purpose}라는 피치 목적을 고려해, STT 과정에서 잘못 변환된 단어들만 수정해. 예를 들어, '코파이엇'을 '코파일럿'으로 수정. 내용 자체를 바꾸지 마. 부연 설명 없이, 업데이트된 텍스트만 리턴해줘. 텍스트: \"\n",
    "    user_prompt = user_base_prompt + stt_chunk\n",
    "    \n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if len(encoding.encode(system_prompt+user_prompt)) <= max_tokens/2:\n",
    "        refined_text = call_gpt(system_prompt, user_prompt, max_tokens)\n",
    "        print(refined_text)\n",
    "        return refined_text\n",
    "    else:\n",
    "        print(\"Token limit exceeded.\")\n",
    "        return stt_chunk\n",
    "\n",
    "\n",
    "\n",
    "def refine_stt(recognized_chunks):\n",
    "    refined_text = \"\"\n",
    "    refined_chunks = []\n",
    "\n",
    "    for chunk in recognized_chunks:\n",
    "        refined_chunk = call_gpt_for_refinement(chunk)\n",
    "        refined_chunks.append(refined_chunk)\n",
    "        refined_text += refined_chunk + \" \"\n",
    "    \n",
    "    return refined_text, refined_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요. 저는 한국 마이크로소프트에서 보안 부분에 대한 전략 수립과 그다음에 사업 운영을 담당하고 있는 박상준이라고 합니다. 오늘 저는 빌드 여러 보안 세션 중에서 마이크로소프트 코파일럿 포스케이트를 통한 멀티 클라우드 데브옵스를 지원하는 방법이 어떤 것이 있는지 설명을 드리고자 합니다.\n",
      "먼저 세션 시작하기 전에 인제 코파일럿 퍼시기 때문에 설명을 좀 먼저 드릴 필요가 있는데요. 코파일럿 시큐리티에 대해서 모르시는 분이 있을 수 있어서 먼저 설명을 간단하게 드리면 전 세계 최초 그리고 유일한 GPT 기반의 생성형 AI 기반 보안 솔루션입니다. 저희가 1년 전쯤에 프리뷰를 발표하였고요. 올해 사월에 정식 출시가 되었습니다. 그 AI를 통해서 고객의 사이버 보안 수준을 혁신적으로 올릴 수 있는 솔루션이 되겠습니다.\n",
      "이 기반에는 어마어마한 데이터를 기반으로 학습되어 있는데요. 약 65조 개 보안 시그널을 통해서 코파일럿 퍼시트를 학습시켰고요. 이를 통해서 머신 스피드하고 스케일로 저희가 지원해 드리는데 이 말은 무슨 말이냐면 굉장히 빠른 속도와 스케일을 통해서 고객을 도와드린다는 얘기고요. 어 이는 마치 우리 옆에 음 초급이나 중급 보안 엔진을 두고 이분들한테 간단한 내용들을 학습시키고 저희 업무를 도움을 주게 하는 형태와 같습니다.\n",
      "어 일반적인 AI와 달리 이거는 이제 기업 전용으로 제공이 되고요. 또 고객의 데이터를 AI 학습용으로 활용하지 않습니다. 그래서 고객의 데이터에 대한 유출 걱정 없이 어 AI를 활용할 수 있습니다. 아울러 이번 빌드에서는 코파일럿 시큐리티에 연동되는 제품이 더 확대되어서 저희가 이제 MDC라고 부르는데요. 어 디펜더 포 클라우드까지 확대가 되었습니다. 요번에는 아직 퍼블릭 미리보기 상태인데요. 이에 대한 자세한 설명을 드리도록 하겠습니다.\n",
      "먼저 동작 방식에 대한 부분을 말씀드리도록 하겠습니다. 어 제목에서 보시면 머신 스피드하고 스케일인데요. 말씀드렸다시피 매우 빠른 속도와 확장성을 갖고 있고요. 어 일반적으로 보안 업무자가 몇 시간 또는 며칠 걸리던 작업들을 어 몇 분 이내 어 완료할 수 있는 것이 되겠고요. 이러한 역량들을 MLOps까지 어 확대했다는 얘기가 되겠습니다. 왼쪽을 보시면 세 가지 베리핏이 있는데요. 먼저 첫 번째는.\n",
      "복잡한 것을 단순화 시킬 수 있습니다. 실제로는 보안 시그널들이 엄청나게 많은데 이런 노이즈를 줄이고 자연어를 이용해서 쉽게 분류하고 대응할 수 있습니다. 어 2번째 특징은 어 놓치는 거 없이 탐지하는 것입니다. 코파일럿과 MDC를 같이 사용하면 보안 관리자들은 노이즈를 필터링함으로써 놓치는 것이 없이 모든 것을 잘 포착하고 빠르게 수정해서 복잡성을 간소화시킬 수 있습니다. 마지막.\n",
      "으로는 빠르게 대응하는 것인데요. 소스 코드 상에서 문제가 있거나 그런 거를 해결하기 위해서 AI가 해결한 액션을 제공해 드리고 있습니다. 이런 것들을 통해서 문제를 빠르게 해결할 수 있습니다. 이에 대한 각각 대한 설명을 다음번에 드리도록 하겠습니다. 먼저 1번째 기능인데요, 위험 사항을 알아보는 것입니다. 고객사 클라우드 환경에서 어떤 부분이 중요하고 위험한지를 빠르게 알려줄 수 있는 건데요. 먼저 오른쪽 화면을 보시면 왼쪽이 이제 MDC 화면이고 오른쪽이 임베디드에 있는 코.\n",
      "화면입니다. 그리고 상단에 보시면 애저 주시 PAWS 뭐 이런 여러 가지 솔루션들이 있습니다. 그래서 왼쪽에서 MDC가 보안 위험 상황에 대해서 정보를 캡처하면 오른쪽에 코파일럿을 갖고 좀 더 세부적인 내용을 물어본다던가 분석한다든가 대응할 수 있게 되겠습니다. 그리고 현재 예시로는 왼쪽에 있는 내용들을 좀 써머리 해라고 했더니 오른쪽에서 예, 그런 내용들을 알려주고 이에 대한 인사이트를 제공해 주고 있습니다.\n",
      "2번째 기능은 리스크 레미데이션인데요. 위험에 대해서 대응해 주는 것을 도와주는 겁니다. 그래서 AI 통합돼 있는 그 레미데이션 기능을 활용해서 권고 사항을 받을 수 있고 이걸 읽어보시고 내용을 이해해서 어 필요한 액션을 취할 수 있습니다. 오른쪽 화면을 잠깐 보시면 어? 이 점 화면에서는 현재 상황에 대한 써머리하고 인사이트 볼 수 있었는데요. 이번에는 코파일럿한테 어떠한 위험성이 있는 벌너빌리티에 관련된 리소스가 어디에 있는지를 물어보라고 했는데.\n",
      "그거에 대해서 조금 더 포커스해서 알려달라라고 명령을 하였구요. 어? 이에 대해서 코파일럿이 알려주고 있음을 확인할 수 있습니다. 마지막으로는 자동화되어 있는 그 위협 레미디에이션 기능인데요. 어 AI 생성된 풀 리퀘스트 기능을 이용하여 그 대규모 시스템에서 코드 위드 컴플라이언스 같은 것들을 수정하게 하는 것입니다. 그 왼쪽에 오른쪽을 보시면 애저 대시보드 상에 문제가 있는 부분을 해결하기 위해서 풀 리퀘스트를 서밋 하겠냐고 물어보게 됩니다. 그래서 이걸 서밋하면 해당 내용들이 어 예전.\n",
      "업데이트가 되고 잘못된 설명을 수정할 수 있습니다.\n",
      "그 정리해 보면 MDC 하고 코파일럿을 통해서 현재의 상태를 확실하게 알 수 있고 어 문제 해결을 위하여 가이드와 자동화된 해결책을 얻을 수 있고요. 어 이를 통해서 이전에 비해서 좀 더 스마트하게 보안 운영을 하실 수 있습니다. 이것이 AI 솔루션인 코파일럿 포 시큐리티하고 클라우드 보안을 위한 마이크로소프트 벤더 포 클라우드의 연동을 통해서 얻을 수 있는 효과입니다.\n",
      "오늘 설명은 여기까지고요. 앞으로도 마이크로소프트 보안에 대해서 지속적으로 관심을 부탁드리겠습니다. 경청해 주셔서 감사합니다.\n"
     ]
    }
   ],
   "source": [
    "refined_text, refined_chunks = refine_stt(recognized_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grounding with Bing Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "BING_SEARCH_ID = os.getenv(\"BING_SEARCH_ID\")\n",
    "BING_SEARCH_NAME = os.getenv(\"BING_SEARCH_NAME\")\n",
    "BING_SEARCH_KEY = os.getenv(\"BING_SEARCH_KEY\")\n",
    "\n",
    "AI_PROJECT_CONNECTION_STRING = os.getenv(\"AI_PROJECT_CONNECTION_STRING\")\n",
    "AI_PROJECT_API_KEY = os.getenv(\"AI_PROJECT_API_KEY\")\n",
    "AOAI_DEPLOYMENT_NAME_GPT_BING = os.getenv(\"AOAI_DEPLOYMENT_NAME_GPT_BING\")\n",
    "AI_PROJECT_NAME = os.getenv(\"AI_PROJECT_NAME\")\n",
    "AI_PROJECT_ENDPOINT = os.getenv(\"AI_PROJECT_ENDPOINT\")\n",
    "AI_PROJECT_ID = os.getenv(\"AI_PROJECT_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_search_agent_name = \"bing-search-agent\"\n",
    "bing_search_agent_instructions = \"\"\"\n",
    "- 유저가 전달한 내용의 정확도를 평가해줘.\n",
    "- 근거는 https://learn.microsoft.com/ko-kr/ 사이트의 최신 정보에서 찾아줘.\n",
    "- 평가에 대한 근거와 citation을 달아줘.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-projects in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (1.0.0b6)\n",
      "Requirement already satisfied: azure-core in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (1.32.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (from azure-ai-projects) (0.7.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (from azure-ai-projects) (4.12.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (from azure-core) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (from azure-core) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (from requests>=2.21.0->azure-core) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (from requests>=2.21.0->azure-core) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (from requests>=2.21.0->azure-core) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\t-suzyvaque\\onedrive - microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\lib\\site-packages (from requests>=2.21.0->azure-core) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-ai-projects azure-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpResponseError",
     "evalue": "(UserError) Identity(object id: d82a8c06-b4c5-4839-8a76-65b555e69ab3) does not have permissions for Microsoft.MachineLearningServices/workspaces/agents/action actions. Please refer to https://aka.ms/azureml-auth-troubleshooting to fix the permissions issue.\nCode: UserError\nMessage: Identity(object id: d82a8c06-b4c5-4839-8a76-65b555e69ab3) does not have permissions for Microsoft.MachineLearningServices/workspaces/agents/action actions. Please refer to https://aka.ms/azureml-auth-troubleshooting to fix the permissions issue.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHttpResponseError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m bing_tool_dict = bing_tool.\u001b[34m__dict__\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Create an agent with Bing Search capabilities\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m agent = \u001b[43mproject_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43magents\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mAOAI_DEPLOYMENT_NAME_GPT_BING\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbing_search_agent_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbing_search_agent_instructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbing_tool_dict\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAgent successfully created with Bing Search grounding!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\t-suzyvaque\\OneDrive - Microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:105\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m span_impl_type = settings.tracing_implementation()\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\t-suzyvaque\\OneDrive - Microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\Lib\\site-packages\\azure\\ai\\projects\\operations\\_patch.py:1062\u001b[39m, in \u001b[36mAgentsOperations.create_agent\u001b[39m\u001b[34m(self, body, model, name, description, instructions, tools, tool_resources, toolset, temperature, top_p, response_format, metadata, content_type, **kwargs)\u001b[39m\n\u001b[32m   1059\u001b[39m     tools = toolset.definitions\n\u001b[32m   1060\u001b[39m     tool_resources = toolset.resources\n\u001b[32m-> \u001b[39m\u001b[32m1062\u001b[39m new_agent = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1064\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1066\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtool_resources\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m toolset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1077\u001b[39m     \u001b[38;5;28mself\u001b[39m._toolset[new_agent.id] = toolset\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\t-suzyvaque\\OneDrive - Microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:105\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m span_impl_type = settings.tracing_implementation()\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\t-suzyvaque\\OneDrive - Microsoft\\바탕 화면\\evalai\\ms-pitch-eval-ai\\evalai_venv\\Lib\\site-packages\\azure\\ai\\projects\\operations\\_operations.py:1757\u001b[39m, in \u001b[36mAgentsOperations.create_agent\u001b[39m\u001b[34m(self, body, model, name, description, instructions, tools, tool_resources, temperature, top_p, response_format, metadata, **kwargs)\u001b[39m\n\u001b[32m   1755\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1756\u001b[39m     map_error(status_code=response.status_code, response=response, error_map=error_map)\n\u001b[32m-> \u001b[39m\u001b[32m1757\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response=response)\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _stream:\n\u001b[32m   1760\u001b[39m     deserialized = response.iter_bytes()\n",
      "\u001b[31mHttpResponseError\u001b[39m: (UserError) Identity(object id: d82a8c06-b4c5-4839-8a76-65b555e69ab3) does not have permissions for Microsoft.MachineLearningServices/workspaces/agents/action actions. Please refer to https://aka.ms/azureml-auth-troubleshooting to fix the permissions issue.\nCode: UserError\nMessage: Identity(object id: d82a8c06-b4c5-4839-8a76-65b555e69ab3) does not have permissions for Microsoft.MachineLearningServices/workspaces/agents/action actions. Please refer to https://aka.ms/azureml-auth-troubleshooting to fix the permissions issue."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "# from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import BingGroundingTool\n",
    "\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    conn_str = AI_PROJECT_CONNECTION_STRING,\n",
    "    credential = DefaultAzureCredential()\n",
    "    # credential = AzureKeyCredential(AI_PROJECT_API_KEY)\n",
    ")\n",
    "\n",
    "# Bing Search connection ID\n",
    "bing_tool = BingGroundingTool(connection_id = BING_SEARCH_ID)\n",
    "bing_tool_dict = bing_tool.__dict__\n",
    "\n",
    "# Create an agent with Bing Search capabilities\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=AOAI_DEPLOYMENT_NAME_GPT_BING,\n",
    "    name=bing_search_agent_name,\n",
    "    instructions=bing_search_agent_instructions,\n",
    "    tools=[bing_tool_dict]\n",
    ")\n",
    "\n",
    "print(\"Agent successfully created with Bing Search grounding!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def call_gpt_for_feedback(text_chunk):\n",
    "    max_tokens = 1000\n",
    "\n",
    "    system_prompt = \"https://learn.microsoft.com/ko-kr/의 최신 정보를 기반으로, 틀린 내용을 지적해줘.\"\n",
    "\n",
    "    user_base_prompt = f\"bullet point로, 완전히 틀린 내용만 그 근거와 함께 간략히 지적해줘. 근거는 https://learn.microsoft.com/ko-kr/에서 찾아. 다른 말은 덧붙이지 마. 텍스트: \"\n",
    "    user_prompt = user_base_prompt + text_chunk\n",
    "    \n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if len(encoding.encode(system_prompt+user_prompt)) <= max_tokens/2:\n",
    "        feedback = call_gpt(system_prompt, user_prompt, max_tokens)\n",
    "        print(feedback)\n",
    "        return feedback\n",
    "    else:\n",
    "        # TODO: Implement chunking for large text\n",
    "        print(\"Token limit exceeded.\")\n",
    "        return \"Token limit exceeded.\"\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Gounding with Bing Search for efficient RAG\n",
    "def grounding_w_bing():\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def run_feedback_flow(chunks):\n",
    "    feedback_text = \"\"\n",
    "\n",
    "    for chunk in chunks:\n",
    "        feedback = call_gpt_for_feedback(chunk)\n",
    "        feedback_text += feedback + \" \"\n",
    "    \n",
    "    return feedback_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_chunks = [\"안녕하세요. 저는 한국 마이크로소프트에서 보안 부분에 대한 전략 수립과 그다음에 사업 운영을 담당하고 있는 박상준이라고 합니다. 오늘 저는 빌드 여러 보안 세션 중에서 마이크로소프트 코파일럿 포스케이트를 통한 멀티 클라우드 데브옵스를 지원하는 방법이 어떤 것이 있는지 설명을 드리고자 합니다.\", \"먼저 세션 시작하기 전에 인제 코파일럿 퍼시기 때문에 설명을 좀 먼저 드릴 필요가 있는데요. 코파일럿 시큐리티에 대해서 모르시는 분이 있을 수 있어서 먼저 설명을 간단하게 드리면 전 세계 최초 그리고 유일한 GPT 기반의 생성형 AI 기반 보안 솔루션입니다. 저희가 1년 전쯤에 프리뷰를 발표하였고요. 올해 사월에 정식 출시가 되었습니다. 그 AI를 통해서 고객의 사이버 보안 수준을 혁신적으로 올릴 수 있는 솔루션이 되겠습니다.\", \"이 기반에는 어마어마한 데이터를 기반으로 학습되어 있는데요. 약 65조 개 보안 시그널을 통해서 코파일럿 퍼시트를 학습시켰고요. 이를 통해서 머신 스피드하고 스케일로 저희가 지원해 드리는데 이 말은 무슨 말이냐면 굉장히 빠른 속도와 스케일을 통해서 고객을 도와드린다는 얘기고요. 어 이는 마치 우리 옆에 음 초급이나 중급 보안 엔진을 두고 이분들한테 간단한 내용들을 학습시키고 저희 업무를 도움을 주게 하는 형태와 같습니다.\", \"어 일반적인 AI와 달리 이거는 이제 기업 전용으로 제공이 되고요. 또 고객의 데이터를 AI 학습용으로 활용하지 않습니다. 그래서 고객의 데이터에 대한 유출 걱정 없이 어 AI를 활용할 수 있습니다. 아울러 이번 빌드에서는 코파일럿 시큐리티에 연동되는 제품이 더 확대되어서 저희가 이제 MDC라고 부르는데요. 어 디펜더 포 클라우드까지 확대가 되었습니다. 요번에는 아직 퍼블릭 미리보기 상태인데요. 이에 대한 자세한 설명을 드리도록 하겠습니다.\", \"먼저 동작 방식에 대한 부분을 말씀드리도록 하겠습니다. 어 제목에서 보시면 머신 스피드하고 스케일인데요. 말씀드렸다시피 매우 빠른 속도와 확장성을 갖고 있고요. 어 일반적으로 보안 업무자가 몇 시간 또는 며칠 걸리던 작업들을 어 몇 분 이내 어 완료할 수 있는 것이 되겠고요. 이러한 역량들을 MLOps까지 어 확대했다는 얘기가 되겠습니다. 왼쪽을 보시면 세 가지 베리핏이 있는데요. 먼저 첫 번째는.\", \"복잡한 것을 단순화 시킬 수 있습니다. 실제로는 보안 시그널들이 엄청나게 많은데 이런 노이즈를 줄이고 자연어를 이용해서 쉽게 분류하고 대응할 수 있습니다. 어 2번째 특징은 어 놓치는 거 없이 탐지하는 것입니다. 코파일럿과 MDC를 같이 사용하면 보안 관리자들은 노이즈를 필터링함으로써 놓치는 것이 없이 모든 것을 잘 포착하고 빠르게 수정해서 복잡성을 간소화시킬 수 있습니다. 마지막.\", \"으로는 빠르게 대응하는 것인데요. 소스 코드 상에서 문제가 있거나 그런 거를 해결하기 위해서 AI가 해결한 액션을 제공해 드리고 있습니다. 이런 것들을 통해서 문제를 빠르게 해결할 수 있습니다. 이에 대한 각각 대한 설명을 다음번에 드리도록 하겠습니다. 먼저 1번째 기능인데요, 위험 사항을 알아보는 것입니다. 고객사 클라우드 환경에서 어떤 부분이 중요하고 위험한지를 빠르게 알려줄 수 있는 건데요. 먼저 오른쪽 화면을 보시면 왼쪽이 이제 MDC 화면이고 오른쪽이 임베디드에 있는 코.\", \"화면입니다. 그리고 상단에 보시면 애저 주시 PAWS 뭐 이런 여러 가지 솔루션들이 있습니다. 그래서 왼쪽에서 MDC가 보안 위험 상황에 대해서 정보를 캡처하면 오른쪽에 코파일럿을 갖고 좀 더 세부적인 내용을 물어본다던가 분석한다든가 대응할 수 있게 되겠습니다. 그리고 현재 예시로는 왼쪽에 있는 내용들을 좀 써머리 해라고 했더니 오른쪽에서 예, 그런 내용들을 알려주고 이에 대한 인사이트를 제공해 주고 있습니다.\", \"2번째 기능은 리스크 레미데이션인데요. 위험에 대해서 대응해 주는 것을 도와주는 겁니다. 그래서 AI 통합돼 있는 그 레미데이션 기능을 활용해서 권고 사항을 받을 수 있고 이걸 읽어보시고 내용을 이해해서 어 필요한 액션을 취할 수 있습니다. 오른쪽 화면을 잠깐 보시면 어? 이 점 화면에서는 현재 상황에 대한 써머리하고 인사이트 볼 수 있었는데요. 이번에는 코파일럿한테 어떠한 위험성이 있는 벌너빌리티에 관련된 리소스가 어디에 있는지를 물어보라고 했는데.\", \"그거에 대해서 조금 더 포커스해서 알려달라라고 명령을 하였구요. 어? 이에 대해서 코파일럿이 알려주고 있음을 확인할 수 있습니다. 마지막으로는 자동화되어 있는 그 위협 레미디에이션 기능인데요. 어 AI 생성된 풀 리퀘스트 기능을 이용하여 그 대규모 시스템에서 코드 위드 컴플라이언스 같은 것들을 수정하게 하는 것입니다. 그 왼쪽에 오른쪽을 보시면 애저 대시보드 상에 문제가 있는 부분을 해결하기 위해서 풀 리퀘스트를 서밋 하겠냐고 물어보게 됩니다. 그래서 이걸 서밋하면 해당 내용들이 어 예전.\", \"업데이트가 되고 잘못된 설명을 수정할 수 있습니다.\", \"그 정리해 보면 MDC 하고 코파일럿을 통해서 현재의 상태를 확실하게 알 수 있고 어 문제 해결을 위하여 가이드와 자동화된 해결책을 얻을 수 있고요. 어 이를 통해서 이전에 비해서 좀 더 스마트하게 보안 운영을 하실 수 있습니다. 이것이 AI 솔루션인 코파일럿 포 시큐리티하고 클라우드 보안을 위한 마이크로소프트 벤더 포 클라우드의 연동을 통해서 얻을 수 있는 효과입니다.\", \"오늘 설명은 여기까지고요. 앞으로도 마이크로소프트 보안에 대해서 지속적으로 관심을 부탁드리겠습니다. 경청해 주셔서 감사합니다.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 틀림: \"마이크로소프트 코파일럿 포스케이트\"는 존재하지 않는 용어입니다.  \n",
      "  근거: https://learn.microsoft.com/ko-kr/에서 \"코파일럿 포스케이트\" 관련 공식 언급 없음.\n",
      "- **\"전 세계 최초 그리고 유일한 GPT 기반의 생성형 AI 기반 보안 솔루션입니다.\"**  \n",
      "  - **근거**: Microsoft의 문서를 확인한 결과, GPT 기반의 생성형 AI를 사용하는 보안 솔루션은 Microsoft Copilot만이 유일하지 않습니다. 다른 업체에서도 GPT 기반의 보안 솔루션이 존재하는 것으로 보입니다. 이 문장은 과장된 표현입니다.  \n",
      "  - 참고: [Microsoft Learn](https://learn.microsoft.com/ko-kr/)\n",
      "\n",
      "- **\"저희가 1년 전쯤에 프리뷰를 발표하였고요.\"**  \n",
      "  - **근거**: 정확한 프리뷰 발표 시점은 Microsoft 관련 공식 문서에 따라 달라질 수 있지만, Copilot 관련 최초 발표는 1년 전보다 더 이전에 이루어졌을 가능성이 있습니다.  \n",
      "  - 참고: [Microsoft Learn](https://learn.microsoft.com/ko-kr/)\n",
      "\n",
      "- **\"올해 사월에 정식 출시가 되었습니다.\"**  \n",
      "  - **근거**: Microsoft Copilot의 정식 출시 날짜는 제품 및 서비스 종류에 따라 다를 수 있습니다. 실제 출시 시점이 올해 4월이 아닐 수 있으므로 공식 문서에서 제공한 출시일을 확인해야 합니다.  \n",
      "  - 참고: [Microsoft 365 Copilot 공식 정보](https://learn.microsoft.com/ko-kr/)\n",
      "- **\"약 65조 개 보안 시그널을 통해서 코파일럿 퍼시트를 학습시켰고요.\"**  \n",
      "  - 근거: Microsoft Learn 공식 문서에서 코파일럿에 대한 설명은 여러 서비스 및 제품에 따라 구체적으로 다르며, \"65조 개의 보안 시그널\"로 학습되었다는 명시적인 언급은 존재하지 않음. (https://learn.microsoft.com/ko-kr/)\n",
      "- \"고객의 데이터를 AI 학습용으로 활용하지 않습니다.\"  \n",
      "  근거: Microsoft의 일부 AI 서비스는 고객의 데이터를 학습 목적으로 사용할 수 있습니다. 예를 들어, [Microsoft의 제품 문서](https://learn.microsoft.com/ko-kr/legal/gdpr/)에 따르면 특정 서비스는 데이터 처리 방식을 명확하게 설명하며, 학습 목적으로 사용하는 경우가 있음을 밝히고 있습니다.  \n",
      "\n",
      "- \"코파일럿 시큐리티에 연동되는 제품이 더 확대되어서 저희가 이제 MDC라고 부르는데요. 어 디펜더 포 클라우드까지 확대가 되었습니다.\"  \n",
      "  근거: Microsoft Defender for Cloud는 현재 코파일럿 기능과 통합되지 않았거나 공식적으로 이에 대한 언급이 없습니다. 최신 관련 내용은 [Defender for Cloud 문서](https://learn.microsoft.com/ko-kr/azure/defender-for-cloud/)에서 확인할 수 있습니다.  \n",
      "- \"이러한 역량들을 MLOps까지 어 확대했다는 얘기가 되겠습니다.\"  \n",
      "  근거: https://learn.microsoft.com/ko-kr/에는 Microsoft의 보안 제품과 관련한 특정 MLOps의 적용 사례 및 확장성에 대한 명확한 언급이 없다. MLOps는 머신 러닝 모델의 라이프사이클 관리에 중점을 두며, 보안 업무와 직접적으로 연결되는 내용은 없음. \n",
      "\n",
      "- \"왼쪽을 보시면 세 가지 베리핏이 있는데요.\"  \n",
      "  근거: 문서 상에서 어떤 특정 '왼쪽' 또는 '베리핏'이라는 표현과 그 구조가 관련 문맥에서 제공되지 않음. 이는 독자에게 명확하지 않으며 혼란을 줄 수 있음.\n",
      "- \"코파일럿과 MDC를 같이 사용하면 보안 관리자들은 노이즈를 필터링함으로써 놓치는 것이 없이 모든 것을 잘 포착하고 빠르게 수정...\"  \n",
      "  **틀린 내용 근거**: Microsoft Defender for Cloud(MDC)와 GitHub Copilot은 각각 클라우드 보안 관리와 개발자 코드 지원 도구로, MDC가 탐지를 보장하거나 모든 노이즈를 필터링한다는 명시적인 기능 설명은 없습니다. ([근거 링크](https://learn.microsoft.com/ko-kr/azure/defender-for-cloud/overview))\n",
      "- **\"AI가 소스 코드 상의 문제를 해결한 액션을 제공한다\"**는 틀렸습니다.  \n",
      "  **근거**: Microsoft의 공식 문서에 따르면, AI 도구는 주로 코드 내에서 문제를 지적하는 데 도움을 주며, 자동으로 해결 방안을 직접 제공하지는 않습니다. 예를 들어, GitHub Copilot은 문제 해결을 돕는 코드 제안을 제공하지만, 완전한 액션을 보장하지 않습니다.  \n",
      "  [[Microsoft Learn - GitHub Copilot](https://learn.microsoft.com/ko-kr/github/copilot/)]\n",
      "\n",
      "- **\"MDC가 위험 사항을 빠르게 알려준다\"**는 틀렸습니다.  \n",
      "  **근거**: Microsoft Defender for Cloud(MDC)는 보안 관련 권고를 제공하고 보안 점수를 개선하기 위한 제안을 보지만, \"위험 사항을 빠르게 알려주는 도구\"로만 작동하지는 않으며 사용자가 능동적으로 대시보드를 확인해야 합니다.  \n",
      "  [[Microsoft Learn - Microsoft Defender for Cloud](https://learn.microsoft.com/ko-kr/azure/defender-for-cloud/overview)]]\n",
      "- \"애저 주시 PAWS\"라는 용어는 존재하지 않습니다. Azure 관련 공식 문서에서 확인할 수 없는 용어입니다. (참고: https://learn.microsoft.com/ko-kr/azure/)  \n",
      "- \"MDC\"라는 약자가 문맥상 Microsoft Defender for Cloud를 지칭하는 것으로 보이나, 문서에서는 \"MDC\"라는 약자를 명시적으로 사용하지 않습니다. (참고: https://learn.microsoft.com/ko-kr/azure/defender-for-cloud/)  \n",
      "- \"코파일럿\"과 관련하여 Microsoft Defender for Cloud와의 직접적인 통합 기능에 대해 설명된 공식 문서가 없습니다. 코파일럿은 주로 GitHub Copilot 및 Microsoft 365 Copilot으로 설명됩니다. (참고: https://learn.microsoft.com/ko-kr/) \n",
      "- **틀린 내용**: \"AI 통합돼 있는 그 레미데이션 기능을 활용해서 권고 사항을 받을 수 있고...\"  \n",
      "  **근거**: https://learn.microsoft.com/ko-kr/ 문서에 따르면, Microsoft에서 제공하는 대부분의 리스크 관리와 레미데이션 관련 도구는 AI 통합 기능을 명시적으로 언급하지 않음. 사용 사례에 따라 통합 형태가 다를 수 있으나, 기본적으로 자동화된 권고 사항 제공은 일반적인 규칙 기반 시스템에 더 가까움.  \n",
      "\n",
      "- **틀린 내용**: \"코파일럿한테 어떠한 위험성이 있는 벌너빌리티에 관련된 리소스가 어디에 있는지를 물어보라고 했는데...\"  \n",
      "  **근거**: https://learn.microsoft.com/ko-kr/ 문서에는 Microsoft Copilot 기능이 직접적인 리스크 레미데이션 및 벌너빌리티 관련 리소스를 탐색하거나 알려주는 역할을 한다는 설명이 없음. Copilot은 일반적으로 문서 생성, 코드 지원 등의 작업에 더 중점을 둠.\n",
      "- \"AI 생성된 풀 리퀘스트 기능을 이용하여 그 대규모 시스템에서 코드 위드 컴플라이언스 같은 것들을 수정하게 하는 것입니다.\"  \n",
      "  근거: Microsoft Copilot 관련 문서에서 현재까지 AI가 생성한 Pull Request가 compliance를 자동으로 수정하는 기능은 명시되어 있지 않습니다. ([참고](https://learn.microsoft.com/ko-kr/azure/))  \n",
      "\n",
      "- \"왼쪽에 오른쪽을 보시면 애저 대시보드 상에 문제가 있는 부분을 해결하기 위해서 풀 리퀘스트를 서밋 하겠냐고 물어보게 됩니다.\"  \n",
      "  근거: Azure Dashboard UI에서는 문제 해결 목적으로 Pull Request 제출을 묻는 기능이 제공되지 않는 것으로 확인됩니다. ([참고](https://learn.microsoft.com/ko-kr/azure/azure-portal/))  \n",
      "- \"업데이트가 되고 잘못된 설명을 수정할 수 있습니다.\": 내용 자체가 불완전하여 특정한 잘못된 설명이 없음을 증명할 수 없음. 근거는 https://learn.microsoft.com/ko-kr/에서 특정 업데이트 주기와 잘못된 설명을 관리하는 절차를 명시하지 않음.\n",
      "- 틀린 내용: \"코파일럿 포 시큐리티\"라는 명칭 사용  \n",
      "  근거: Microsoft Learn에서는 \"Microsoft Security Copilot\"으로 명시되어 있음. \"코파일럿 포 시큐리티\"는 공식 명칭이 아님.  \n",
      "  (출처: [Microsoft Security Copilot 정보](https://learn.microsoft.com/ko-kr/))\n",
      "- 해당 텍스트에는 기술적인 정보나 주장되는 사실이 포함되어 있지 않아, Microsoft Learn의 내용을 기준으로 \"완전히 틀린 내용\"이라고 지적할 사항이 없습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'- 틀림: \"마이크로소프트 코파일럿 포스케이트\"는 존재하지 않는 용어입니다.  \\n  근거: https://learn.microsoft.com/ko-kr/에서 \"코파일럿 포스케이트\" 관련 공식 언급 없음. - **\"전 세계 최초 그리고 유일한 GPT 기반의 생성형 AI 기반 보안 솔루션입니다.\"**  \\n  - **근거**: Microsoft의 문서를 확인한 결과, GPT 기반의 생성형 AI를 사용하는 보안 솔루션은 Microsoft Copilot만이 유일하지 않습니다. 다른 업체에서도 GPT 기반의 보안 솔루션이 존재하는 것으로 보입니다. 이 문장은 과장된 표현입니다.  \\n  - 참고: [Microsoft Learn](https://learn.microsoft.com/ko-kr/)\\n\\n- **\"저희가 1년 전쯤에 프리뷰를 발표하였고요.\"**  \\n  - **근거**: 정확한 프리뷰 발표 시점은 Microsoft 관련 공식 문서에 따라 달라질 수 있지만, Copilot 관련 최초 발표는 1년 전보다 더 이전에 이루어졌을 가능성이 있습니다.  \\n  - 참고: [Microsoft Learn](https://learn.microsoft.com/ko-kr/)\\n\\n- **\"올해 사월에 정식 출시가 되었습니다.\"**  \\n  - **근거**: Microsoft Copilot의 정식 출시 날짜는 제품 및 서비스 종류에 따라 다를 수 있습니다. 실제 출시 시점이 올해 4월이 아닐 수 있으므로 공식 문서에서 제공한 출시일을 확인해야 합니다.  \\n  - 참고: [Microsoft 365 Copilot 공식 정보](https://learn.microsoft.com/ko-kr/) - **\"약 65조 개 보안 시그널을 통해서 코파일럿 퍼시트를 학습시켰고요.\"**  \\n  - 근거: Microsoft Learn 공식 문서에서 코파일럿에 대한 설명은 여러 서비스 및 제품에 따라 구체적으로 다르며, \"65조 개의 보안 시그널\"로 학습되었다는 명시적인 언급은 존재하지 않음. (https://learn.microsoft.com/ko-kr/) - \"고객의 데이터를 AI 학습용으로 활용하지 않습니다.\"  \\n  근거: Microsoft의 일부 AI 서비스는 고객의 데이터를 학습 목적으로 사용할 수 있습니다. 예를 들어, [Microsoft의 제품 문서](https://learn.microsoft.com/ko-kr/legal/gdpr/)에 따르면 특정 서비스는 데이터 처리 방식을 명확하게 설명하며, 학습 목적으로 사용하는 경우가 있음을 밝히고 있습니다.  \\n\\n- \"코파일럿 시큐리티에 연동되는 제품이 더 확대되어서 저희가 이제 MDC라고 부르는데요. 어 디펜더 포 클라우드까지 확대가 되었습니다.\"  \\n  근거: Microsoft Defender for Cloud는 현재 코파일럿 기능과 통합되지 않았거나 공식적으로 이에 대한 언급이 없습니다. 최신 관련 내용은 [Defender for Cloud 문서](https://learn.microsoft.com/ko-kr/azure/defender-for-cloud/)에서 확인할 수 있습니다.   - \"이러한 역량들을 MLOps까지 어 확대했다는 얘기가 되겠습니다.\"  \\n  근거: https://learn.microsoft.com/ko-kr/에는 Microsoft의 보안 제품과 관련한 특정 MLOps의 적용 사례 및 확장성에 대한 명확한 언급이 없다. MLOps는 머신 러닝 모델의 라이프사이클 관리에 중점을 두며, 보안 업무와 직접적으로 연결되는 내용은 없음. \\n\\n- \"왼쪽을 보시면 세 가지 베리핏이 있는데요.\"  \\n  근거: 문서 상에서 어떤 특정 \\'왼쪽\\' 또는 \\'베리핏\\'이라는 표현과 그 구조가 관련 문맥에서 제공되지 않음. 이는 독자에게 명확하지 않으며 혼란을 줄 수 있음. - \"코파일럿과 MDC를 같이 사용하면 보안 관리자들은 노이즈를 필터링함으로써 놓치는 것이 없이 모든 것을 잘 포착하고 빠르게 수정...\"  \\n  **틀린 내용 근거**: Microsoft Defender for Cloud(MDC)와 GitHub Copilot은 각각 클라우드 보안 관리와 개발자 코드 지원 도구로, MDC가 탐지를 보장하거나 모든 노이즈를 필터링한다는 명시적인 기능 설명은 없습니다. ([근거 링크](https://learn.microsoft.com/ko-kr/azure/defender-for-cloud/overview)) - **\"AI가 소스 코드 상의 문제를 해결한 액션을 제공한다\"**는 틀렸습니다.  \\n  **근거**: Microsoft의 공식 문서에 따르면, AI 도구는 주로 코드 내에서 문제를 지적하는 데 도움을 주며, 자동으로 해결 방안을 직접 제공하지는 않습니다. 예를 들어, GitHub Copilot은 문제 해결을 돕는 코드 제안을 제공하지만, 완전한 액션을 보장하지 않습니다.  \\n  [[Microsoft Learn - GitHub Copilot](https://learn.microsoft.com/ko-kr/github/copilot/)]\\n\\n- **\"MDC가 위험 사항을 빠르게 알려준다\"**는 틀렸습니다.  \\n  **근거**: Microsoft Defender for Cloud(MDC)는 보안 관련 권고를 제공하고 보안 점수를 개선하기 위한 제안을 보지만, \"위험 사항을 빠르게 알려주는 도구\"로만 작동하지는 않으며 사용자가 능동적으로 대시보드를 확인해야 합니다.  \\n  [[Microsoft Learn - Microsoft Defender for Cloud](https://learn.microsoft.com/ko-kr/azure/defender-for-cloud/overview)]] - \"애저 주시 PAWS\"라는 용어는 존재하지 않습니다. Azure 관련 공식 문서에서 확인할 수 없는 용어입니다. (참고: https://learn.microsoft.com/ko-kr/azure/)  \\n- \"MDC\"라는 약자가 문맥상 Microsoft Defender for Cloud를 지칭하는 것으로 보이나, 문서에서는 \"MDC\"라는 약자를 명시적으로 사용하지 않습니다. (참고: https://learn.microsoft.com/ko-kr/azure/defender-for-cloud/)  \\n- \"코파일럿\"과 관련하여 Microsoft Defender for Cloud와의 직접적인 통합 기능에 대해 설명된 공식 문서가 없습니다. 코파일럿은 주로 GitHub Copilot 및 Microsoft 365 Copilot으로 설명됩니다. (참고: https://learn.microsoft.com/ko-kr/)  - **틀린 내용**: \"AI 통합돼 있는 그 레미데이션 기능을 활용해서 권고 사항을 받을 수 있고...\"  \\n  **근거**: https://learn.microsoft.com/ko-kr/ 문서에 따르면, Microsoft에서 제공하는 대부분의 리스크 관리와 레미데이션 관련 도구는 AI 통합 기능을 명시적으로 언급하지 않음. 사용 사례에 따라 통합 형태가 다를 수 있으나, 기본적으로 자동화된 권고 사항 제공은 일반적인 규칙 기반 시스템에 더 가까움.  \\n\\n- **틀린 내용**: \"코파일럿한테 어떠한 위험성이 있는 벌너빌리티에 관련된 리소스가 어디에 있는지를 물어보라고 했는데...\"  \\n  **근거**: https://learn.microsoft.com/ko-kr/ 문서에는 Microsoft Copilot 기능이 직접적인 리스크 레미데이션 및 벌너빌리티 관련 리소스를 탐색하거나 알려주는 역할을 한다는 설명이 없음. Copilot은 일반적으로 문서 생성, 코드 지원 등의 작업에 더 중점을 둠. - \"AI 생성된 풀 리퀘스트 기능을 이용하여 그 대규모 시스템에서 코드 위드 컴플라이언스 같은 것들을 수정하게 하는 것입니다.\"  \\n  근거: Microsoft Copilot 관련 문서에서 현재까지 AI가 생성한 Pull Request가 compliance를 자동으로 수정하는 기능은 명시되어 있지 않습니다. ([참고](https://learn.microsoft.com/ko-kr/azure/))  \\n\\n- \"왼쪽에 오른쪽을 보시면 애저 대시보드 상에 문제가 있는 부분을 해결하기 위해서 풀 리퀘스트를 서밋 하겠냐고 물어보게 됩니다.\"  \\n  근거: Azure Dashboard UI에서는 문제 해결 목적으로 Pull Request 제출을 묻는 기능이 제공되지 않는 것으로 확인됩니다. ([참고](https://learn.microsoft.com/ko-kr/azure/azure-portal/))   - \"업데이트가 되고 잘못된 설명을 수정할 수 있습니다.\": 내용 자체가 불완전하여 특정한 잘못된 설명이 없음을 증명할 수 없음. 근거는 https://learn.microsoft.com/ko-kr/에서 특정 업데이트 주기와 잘못된 설명을 관리하는 절차를 명시하지 않음. - 틀린 내용: \"코파일럿 포 시큐리티\"라는 명칭 사용  \\n  근거: Microsoft Learn에서는 \"Microsoft Security Copilot\"으로 명시되어 있음. \"코파일럿 포 시큐리티\"는 공식 명칭이 아님.  \\n  (출처: [Microsoft Security Copilot 정보](https://learn.microsoft.com/ko-kr/)) - 해당 텍스트에는 기술적인 정보나 주장되는 사실이 포함되어 있지 않아, Microsoft Learn의 내용을 기준으로 \"완전히 틀린 내용\"이라고 지적할 사항이 없습니다. '"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_feedback_flow(refined_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "AUDIO_FILE_PATH = os.getenv(\"AUDIO_FILE_PATH\")\n",
    "AUDIO_FILE_NAME = os.getenv(\"AUDIO_FILE_NAME\")\n",
    "AOAI_ENDPOINT_GPT = os.getenv(\"AOAI_ENDPOINT_GPT\")\n",
    "AOAI_ENDPOINT_GPT_0513 = os.getenv(\"AOAI_ENDPOINT_GPT_0513\")\n",
    "AOAI_ENDPOINT_WHISPER = os.getenv(\"AOAI_ENDPOINT_WHISPER\")\n",
    "AOAI_API_KEY = os.getenv(\"AOAI_API_KEY\")\n",
    "\n",
    "AI_SERVICES_SPEECH_KEY = os.getenv(\"AI_SERVICES_SPEECH_KEY\")\n",
    "AI_SERVICES_SPEECH_REGION = os.getenv(\"AI_SERVICES_SPEECH_REGION\")\n",
    "AI_SERVICES_SPEECH_ENDPOINT = os.getenv(\"AI_SERVICES_SPEECH_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네, 안녕하세요. 에듀피셜 김종욱입니다. 자 일편에서는 애저 머신 러닝의 두 가지 기능 아주 잘 설명해드렸는데 잘 보시고 오셨죠? 안 보시고 오셨다면 그것부터 보시고 오는 것도 굉장히 좋을 것 같습니다. 자, 이번 시간에 계속 이어서 애저 머신 러닝 이야기를 해드릴 텐데요. 지금 제가 해드리는 내용들을 보고 아 이런 것도 되는구나라고 깜짝 놀라신 분들이라면 바로 애저 머신러닝을 지금 바로 웹 브라우저에 검색을 해서 보신다면 더.\n",
      "많은 정보, 그리고 또 아주 친절하게 한글로 다 번역되어 있는 정보들이 널려 있으니까. 네, 그런 부분들도 함께 참조해 주시면 좋을 것 같습니다.\n",
      "자, 오늘 이야기들을 계속해서 진행하다 보면 앞에서 제가 머신 러닝 프로세스가 되게 많이 복잡해졌다, 이런 얘기들을 했었는데요. 소프트웨어 개발 같은 경우는 이런 복잡함을 그리고 또 지속적인 개발, 그리고 또 지속적인 배포 이런 부분들을 해결하기 위해서 데브옵스라는 장르가 굉장히 많이 발전했죠. 실제로 이 데브옵스는 지금 현재 성공적으로 여러 가지 기술들하고 같이 접목되어서 사용이 되고 있는데요.\n",
      "Azure Machine Learning도 이제는 초기가 벗어나서 운영, 다시 말해서 프로덕션 영역이 점점 더 중요하게 되면서 다시 말해서 ML과 그리고 오퍼레이션을 합쳐서 ML 옵스라고 하는 장르가 극적으로 발전하고 있습니다. 자 문제는 ML 옵스라는 이 장르가 하다 보면 데이터를 수집하고 파이프라인 만들고 이런 분야부터 시작해서 학습해서 모델 만들고 배포하고 운영하는 단계까지 가다 보니까 상대적으로 데브옵스에 비해서는 좀 더 긴.\n",
      "더 긴 프로세스를 갖고 있다는 게 하나의 차이점이라고 얘기를 할 수가 있겠죠. 그래서 이 에멜옵스를 하다 보니까 필요한 부분들이 너무 많아지는 거예요. 그래서 각자 자기가 필요한 프로세스들을 하나씩 만들고 또 필요한 유틸리티들을 만들고 서비스를 만들고 하다 보니까 사실 이 에멜옵스로 여러분들이 검색을 해보시면 굉장히 중요한 단어이기도 하구요. 그리고 지금 이제 가장 트렌디한 단어이기도 하지만 네 관련돼 있는 서비스의 목록과 리스트를 본다면 어마어마하게 많은 오픈소스와 서비스들을 보실 수가 있을 겁니다.\n",
      "말해서 이 엠엘옵스는 지금 현재 춘추 전국 시대라고 할 수가 있습니다. 어디서부터 시작을 해야 될지, 어떤 소프트웨어들을 사용해야 될지, 그리고 이거 버전은 어떻게 맞춰야 될지 이런 부분들이 굉장히 많이 고민이 된다는 거죠. 이런 고민들을 해결하기 위해서 네 여러 가지 서비스를 사용했다 보면 이 서비스들 사이에 뭔가 하나가 틀어지거나 아니면 하나가 업데이트되거나 하나가 연결이 안 되거나 하면 그것 때문에 이 시스템을 유지하고 운영하고 보수하는 데에.\n",
      "노력이 굉장히 많이 들어간다는 겁니다. 요즘 시대가 어떻습니까? 네 클라우드 비용보다 인건비가 제일 비싼 시대잖아요. 그래서 인적자원을 최대한 세이브할 수 있는 네, 그런 기술들이 많이 필요하게 되는데요. 그럴 때 우리는 고민을 어디서 풀 수가 있을까요? 바로 클라우드에서 해결할 수가 있습니다. 네, 클라우드에서는 가장 안정적인, 그리고 가장 최신의 기술들이 녹아 있는 곳이 바로 클라우드라고 할 수가 있겠죠. 그래서.\n",
      "클라우드에서 엠엘옵스로 운영을 한다면 네 바로 클라우드에서 지원되는 여러 가지 서비스들을 이용을 해서 네 인건비와 노력을 많이 세이브할 수 있고요. 그리고 또 가장 안정적으로 엠엘옵스를 운영을 할 수 있게 됩니다. 자, 그런데 이런 것들을 자동화시키고 운영을 한다라고 하면 모든 것들을 다 만들어 드릴 수는 없잖아요? 네, 그러다 보니까 네 각각의 서비스를 그 회사가 원하는 니즈와 그 회사가 원하는 타이밍에 맞춰서 운영을 할 필요가 있습니다.\n",
      "자 그래서 애저 머신러닝에서는 이 전체 과정을 각각의 중요한 서비스들을 다 쪼개놨고요. 그리고 쪼개져 있는 그 서비스들을 하나하나 다 운영하고 관리할 수 있는 파이썬 SDK를 함께 제공을 하고 있습니다. 다시 말해서 이 파이썬 코드를 이용해서 전체 이 MLOps의 과정을 딱 운영을 하고 그리고 만들어진 모델들을 다 관리하고 각각의 버전들을 연결해서 평가하고.\n",
      "좋은 모델이 있다면 그걸 바로 배포해서 운영하는 전체 단계를 하나의 프로세스로 각자 고객의 입맛에 맞춰서 원하는 타이밍에 할 수 있게끔 서비스와 SDK로 만들어놨다는 게 가장 큰 장점이라고 할 수가 있습니다. 자, 여기까지 얘기하면 이거 어떻게 하는 건지 되게 궁금하시죠? 네, 앞선 영상에서 제가 두 가지 기능을 설명해 드렸죠. 디자이너하고 그렇죠. 오토메이티드 ML 이렇게 두 가지를 설명을 해드렸는데 자 이번 시간에.\n",
      "는 노트북을 이용을 해서 이 부분을 어떻게 사용하는지 설명을 해드리도록 하겠습니다. 자 이 노트북에서 보면 우리가 파이썬 코드를 이렇게 작성을 하는데 자 먼저 미리 제가 작성을 해놓은 코드가 있습니다. 자 이 코드에 보시면 제1 먼저 Azure 머신 러닝에서 사용되는 워크스페이스를 먼저 만들어 놨구요. 여기에 사용되는 이 파이썬 라이브러리나 이런 것들은 패키지가 이미 이 노트북에 다 탑재가 되어 있습니다. 그래서 뭐 별도로 임포트를 하거나 하실 필요 없이 네 관련.\n",
      "자, 그다음에 우리가 참조할 만한 데이터를 먼저 불러오고 있는데 뭐 굉장히 유명한 교과서적인 데이터를 불러오고 있죠. 그래서 이 데이터를 불러왔으면 이 데이터를 가지고 이제 실제로 실험을 하는 부분들이 나옵니다. 자 이 실험은 여기 자세히 보시면은 알파 값이 0.1에서 4.0까지 총 열 번의 반복을 할 수 있게끔 그렇게 했고요. 이렇게 실험을 계속 돌리다 보면 클라우드에서 제공되는 강력한 인프라를 이용을 해서.\n",
      "많이 단축시킬 수가 있을 겁니다. 그래서 각각에 맞는 네 자기한테 맞는 보철 머신을 생성을 해서 그 컴퓨팅 파워로 바로 계산하실 수가 있겠죠? 자, 지금 보면 열 번의 계산이 끝났어요. 이 열 번의 계산이 끝났으면 각각의 모델들이 어디에 있는지 궁금하죠? 그죠. 이 열 번에 대해서 각각의 평가 지표도 다 다르게 나올 거고요. 모델들은 이미 바이너리로 네, 그렇습니다. 애저 머신러닝 안에 다 세이브가 돼있어요. 지금 들어가 보시면 이 실험이 바로 보이죠. 이 실험 안에 들어가 보시면.\n",
      "이렇게 열 번의 실험 결과가 바로 이렇게 리스트 업 돼있고요. 이 안에 들어가 보시면 각각의 실험마다 만들어진 모델에 대한 매출액이 따로 따로 준비가 되어있는 것을 볼 수가 있습니다. 자, 이걸 보고 우리가 아 요? 모델이 이 정도면 성능은 좋은데 실제로 운영할 때는 좀 문제가 있을 것 같애라고 해서 이 안에서 내가 좋은 것을 바로 선택을 할 수가 있는데요. 이런 것들도 역시.\n",
      "사람이 아는 게 아니라 기계적으로 바로 사용을 하실 수가 있을 겁니다. 자, 다시 노트북으로 한번 들어가 볼게요. 노트북으로 돌아가 보시면 이번에는 이 만들어진 이 모델을 가지고 평가는 그런 부분들을 볼 수가 있는데요. 자, 지금 다시 돌아가서 봤더니 만들어져 있는 모델 열 개가 폴더 안에 예쁘게 들어가 있는 것이 보이죠. 여기서는 사이킷런을 이용을 했기 때문에 PKL 이라고 하는 확장자로 만들어져 있는 파일들의 목록을 바로 보실 수가 있습니다. 지금.\n",
      "실험에 대한 메트릭을 바로 보실 수가 있고요. 네, 거기 화면에 보면 링크가 있죠. 그 링크를 눌러보시면은 이 실험의 목록으로 바로 접근하는 것도 가능합니다. 물론 이건 사람이 할 때 사용하는 거고, 나중에 운영을 할 때는 데이터가 들어오면 이 프로세스 전체가 실제로 빠르게 진행될 수 있게끔 네 전체에 사람이 개입 없이 자동화시킬 수가 있습니다. 자, 이제는 이 모델들을 평가하는 방법들이 나오는데요. 이 평가하는 방법을 이렇게 돌려보면 이 전체의 내용들을 평가해 보고.\n",
      "네, 그중에서 베스트 모델을 뽑아내는 것을 보실 수가 있습니다. 자 베스트 모델을 받았다면 이걸 바로 다운로드도 가능하겠죠. 네, 이걸 이용을 해서 바로 배포할 수 있는 배포 모델을 만드는 것도 가능합니다. 자 Azure에는 네 실제로 컨테이너뿐만 아니라 ML과 관련돼 있는 굉장히 많은 서비스들이 있어요. 그래서 여기서 바로 우리가 모델을 만들고 컨테이너라이징해서 네 도커 컨테이너로 만들고 이걸 바로 배포해서 운영.\n",
      "정체 과정을 이렇게 하나의 프로세스로 묶어서 진행을 할 수가 있다는 겁니다. 자, 이런 것들에서 보면 기존에 굉장히 많은 오픈소스를 연결해 놓고 네 이게 정말로 한쪽이 뭔가 무너질까 굉장히 많이 고생을 하면서 사용을 하셨을 텐데 이렇게 파이썬으로 네? 실제로 실험부터 시작을 해서 네 데이터 정리 그리고 배포 운영하는 이 전체 단계를 할 수 있다는 것만으로도 굉장히 많은 네.\n",
      "부가적인 노력들을 많이 세이브를 할 수가 있고요. 그렇게 세이브된 노력들을 이용을 해서 우리는 점점 더 더 좋은 모델, 점점 더 좋은 서비스를 만드는 데 그 노력과 힘을 집중을 할 수가 있을 겁니다. 자, 여기서 우리가 만들어진 모델을 바로 배포하고 운영하는 그런 단계까지 이 영상에서 우리가 확인해 보실 수가 있는데 자 우리가 그러면은 왜 이런 서비스를 써야 될까요? 네 당연히.\n",
      "우리는 어떤 머신 러닝을 운영하는 데 있어서 충분한 인적 자원이 확보되지 않는 경우들이 많이 있고요. 그리고 또 개개인 별로 머신러닝이나 이 전체 운영에 관련돼 있어서 기술의 차이 그리고 스킬의 차이가 조금씩 있습니다. 그래서 제대로 제대로 되어있는 프로세스를 만들고 이걸 운영하는 게 무엇보다 중요하다라고 얘기를 할 수가 있겠죠? 자, 이번 시간에는 이렇게 Azure 머신 러닝 서비스에서 노트북스를 이용을 해서 네 전체적인.\n",
      "프로세스를 바로 파이썬 코드로 만들고 운영하는 부분을 제가 설명을 해드렸는데요. 자, 이거 보시고 굉장히 재밌다. 생각하시는 분들은 지금이라도 당장 네 애저 포탈에 들어가서 애저 머신 러닝 서비스를 만들어 보시고 거기에는 설명서들을 읽어보시면 또 다른 새로운 재미들을 많이 보실 수가 있을 겁니다. 자, 오늘은 여기까지 애저 머신 러닝에 대해서 설명을 해드렸습니다. 구독 좋아요.\n",
      "알림 설정까지 지금까지 김영옥이었습니다. 네, 감사합니다.\n"
     ]
    }
   ],
   "source": [
    "#recognized_text, recognized_chunks = call_stt(\"AML_process.wav\")\n",
    "refined_text, refined_chunks = refine_stt(recognized_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_chunks = [\n",
    "\"안녕하세요. 저는 한국 마이크로소프트에서 보안 부분에 대한 전략 수립과 그다음에 사업 운영을 담당하고 있는 박상준이라고 합니다. 오늘 저는 빌드 여러 보안 세션 중에서 마이크로소프트 코파일럿 포스케이트를 통한 멀티 클라우드 데브옵스를 지원하는 방법이 어떤 것이 있는지 설명을 드리고자 합니다.\",\n",
    "\"먼저 세션 시작하기 전에 인제 코파일럿 퍼시기 때문에 설명을 좀 먼저 드릴 필요가 있는데요. 코파일럿 시큐리티에 대해서 모르시는 분이 있을 수 있어서 먼저 설명을 간단하게 드리면 전 세계 최초 그리고 유일한 GPT 기반의 생성형 AI 기반 보안 솔루션입니다. 저희가 1년 전쯤에 프리뷰를 발표하였고요. 올해 사월에 정식 출시가 되었습니다. 그 AI를 통해서 고객의 사이버 보안 수준을 혁신적으로 올릴 수 있는 솔루션이 되겠습니다.\",\n",
    "\"이 기반에는 어마어마한 데이터를 기반으로 학습되어 있는데요. 약 65조 개 보안 시그널을 통해서 코파일럿 퍼시트를 학습시켰고요. 이를 통해서 머신 스피드하고 스케일로 저희가 지원해 드리는데 이 말은 무슨 말이냐면 굉장히 빠른 속도와 스케일을 통해서 고객을 도와드린다는 얘기고요. 어 이는 마치 우리 옆에 음 초급이나 중급 보안 엔진을 두고 이분들한테 간단한 내용들을 학습시키고 저희 업무를 도움을 주게 하는 형태와 같습니다.\",\n",
    "\"어 일반적인 AI와 달리 이거는 이제 기업 전용으로 제공이 되고요. 또 고객의 데이터를 AI 학습용으로 활용하지 않습니다. 그래서 고객의 데이터에 대한 유출 걱정 없이 어 AI를 활용할 수 있습니다. 아울러 이번 빌드에서는 코파일럿 시큐리티에 연동되는 제품이 더 확대되어서 저희가 이제 MDC라고 부르는데요. 어 디펜더 포 클라우드까지 확대가 되었습니다. 요번에는 아직 퍼블릭 미리보기 상태인데요. 이에 대한 자세한 설명을 드리도록 하겠습니다.\",\n",
    "\"먼저 동작 방식에 대한 부분을 말씀드리도록 하겠습니다. 어 제목에서 보시면 머신 스피드하고 스케일인데요. 말씀드렸다시피 매우 빠른 속도와 확장성을 갖고 있고요. 어 일반적으로 보안 업무자가 몇 시간 또는 며칠 걸리던 작업들을 어 몇 분 이내 어 완료할 수 있는 것이 되겠고요. 이러한 역량들을 MLOps까지 어 확대했다는 얘기가 되겠습니다. 왼쪽을 보시면 세 가지 베리핏이 있는데요. 먼저 첫 번째는.\",\n",
    "\"복잡한 것을 단순화 시킬 수 있습니다. 실제로는 보안 시그널들이 엄청나게 많은데 이런 노이즈를 줄이고 자연어를 이용해서 쉽게 분류하고 대응할 수 있습니다. 어 2번째 특징은 어 놓치는 거 없이 탐지하는 것입니다. 코파일럿과 MDC를 같이 사용하면 보안 관리자들은 노이즈를 필터링함으로써 놓치는 것이 없이 모든 것을 잘 포착하고 빠르게 수정해서 복잡성을 간소화시킬 수 있습니다. 마지막.\",\n",
    "\"으로는 빠르게 대응하는 것인데요. 소스 코드 상에서 문제가 있거나 그런 거를 해결하기 위해서 AI가 해결한 액션을 제공해 드리고 있습니다. 이런 것들을 통해서 문제를 빠르게 해결할 수 있습니다. 이에 대한 각각 대한 설명을 다음번에 드리도록 하겠습니다. 먼저 1번째 기능인데요, 위험 사항을 알아보는 것입니다. 고객사 클라우드 환경에서 어떤 부분이 중요하고 위험한지를 빠르게 알려줄 수 있는 건데요. 먼저 오른쪽 화면을 보시면 왼쪽이 이제 MDC 화면이고 오른쪽이 임베디드에 있는 코.\",\n",
    "\"화면입니다. 그리고 상단에 보시면 애저 주시 PAWS 뭐 이런 여러 가지 솔루션들이 있습니다. 그래서 왼쪽에서 MDC가 보안 위험 상황에 대해서 정보를 캡처하면 오른쪽에 코파일럿을 갖고 좀 더 세부적인 내용을 물어본다던가 분석한다든가 대응할 수 있게 되겠습니다. 그리고 현재 예시로는 왼쪽에 있는 내용들을 좀 써머리 해라고 했더니 오른쪽에서 예, 그런 내용들을 알려주고 이에 대한 인사이트를 제공해 주고 있습니다.\",\n",
    "\"2번째 기능은 리스크 레미데이션인데요. 위험에 대해서 대응해 주는 것을 도와주는 겁니다. 그래서 AI 통합돼 있는 그 레미데이션 기능을 활용해서 권고 사항을 받을 수 있고 이걸 읽어보시고 내용을 이해해서 어 필요한 액션을 취할 수 있습니다. 오른쪽 화면을 잠깐 보시면 어? 이 점 화면에서는 현재 상황에 대한 써머리하고 인사이트 볼 수 있었는데요. 이번에는 코파일럿한테 어떠한 위험성이 있는 벌너빌리티에 관련된 리소스가 어디에 있는지를 물어보라고 했는데.\",\n",
    "\"그거에 대해서 조금 더 포커스해서 알려달라라고 명령을 하였구요. 어? 이에 대해서 코파일럿이 알려주고 있음을 확인할 수 있습니다. 마지막으로는 자동화되어 있는 그 위협 레미디에이션 기능인데요. 어 AI 생성된 풀 리퀘스트 기능을 이용하여 그 대규모 시스템에서 코드 위드 컴플라이언스 같은 것들을 수정하게 하는 것입니다. 그 왼쪽에 오른쪽을 보시면 애저 대시보드 상에 문제가 있는 부분을 해결하기 위해서 풀 리퀘스트를 서밋 하겠냐고 물어보게 됩니다. 그래서 이걸 서밋하면 해당 내용들이 어 예전.\",\n",
    "\"업데이트가 되고 잘못된 설명을 수정할 수 있습니다.\",\n",
    "\"그 정리해 보면 MDC 하고 코파일럿을 통해서 현재의 상태를 확실하게 알 수 있고 어 문제 해결을 위하여 가이드와 자동화된 해결책을 얻을 수 있고요. 어 이를 통해서 이전에 비해서 좀 더 스마트하게 보안 운영을 하실 수 있습니다. 이것이 AI 솔루션인 코파일럿 포 시큐리티하고 클라우드 보안을 위한 마이크로소프트 벤더 포 클라우드의 연동을 통해서 얻을 수 있는 효과입니다.\",\n",
    "\"오늘 설명은 여기까지고요. 앞으로도 마이크로소프트 보안에 대해서 지속적으로 관심을 부탁드리겠습니다. 경청해 주셔서 감사합니다.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "def call_gpt(system_prompt, user_prompt, max_tokens = 500):\n",
    "    \"\"\"\n",
    "    Function to generate text using GPT-4o chat completion.\n",
    "    \n",
    "    Args:\n",
    "        system_prompt (str): System prompt.\n",
    "        user_prompt (str): User prompt.\n",
    "        max_tokens (int): Maximum number of tokens to generate, default is 500.\n",
    "    Returns:\n",
    "        result (str): Generated text.\n",
    "    \n",
    "    * Uses Azure AI Services OpenAI\n",
    "    \"\"\"\n",
    "        \n",
    "    aoai_client_gpt = AzureOpenAI(\n",
    "        api_key = os.getenv(\"AOAI_API_KEY\"),  \n",
    "        api_version = \"2024-02-01\",\n",
    "        azure_endpoint = os.getenv(\"AOAI_ENDPOINT_GPT\")\n",
    "    )\n",
    "\n",
    "    gpt_input = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    response = aoai_client_gpt.chat.completions.create(\n",
    "        messages = gpt_input,            \n",
    "        model = \"gpt-4o\",\n",
    "        max_tokens = max_tokens\n",
    "    )\n",
    "\n",
    "    result = response.choices[0].message.content\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def call_gpt_for_feedback(text_chunk):\n",
    "    max_tokens = 1000\n",
    "\n",
    "    system_prompt = \"mslearn에서 검색한 최신 정보를 기반으로, 틀린 내용을 지적해줘.\"\n",
    "\n",
    "    user_base_prompt = f\"명칭이나 개수에 대한 사소한 지적은 하지 마. 맥락을 고려했을 때에도 기능 설명 자체가 명백히 틀린 것만 지적해줘. 근거는 mslearn 사이트에서 찾고 citation을 붙여줘. - bullet point로 지적을 정리해줘. bullet point 외의 설명은 하지 마. 텍스트: \"\n",
    "    user_prompt = user_base_prompt + text_chunk\n",
    "    \n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if len(encoding.encode(system_prompt+user_prompt)) <= max_tokens/2:\n",
    "        feedback = call_gpt(system_prompt, user_prompt, max_tokens)\n",
    "        print(feedback)\n",
    "        return feedback\n",
    "    else:\n",
    "        # TODO: Implement chunking for large text\n",
    "        print(\"Token limit exceeded.\")\n",
    "        return \"Token limit exceeded.\"\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Gounding with Bing Search for efficient RAG\n",
    "def grounding_w_bing():\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def run_feedback_flow(chunks):\n",
    "    feedback_text = \"\"\n",
    "\n",
    "    for chunk in chunks:\n",
    "        feedback = call_gpt_for_feedback(chunk)\n",
    "        feedback_text += feedback + \" \"\n",
    "    \n",
    "    return feedback_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지적할 내용이 없습니다. 작성하신 텍스트가 명백히 틀린 정보를 담고 있지 않습니다. MS Learn 사이트를 기반으로도 이 내용은 사실과 일치합니다.\n",
      "- \"데브옵스는 소프트웨어 개발의 복잡함을 해결하기 위해 발전한 장르\"라는 내용은 틀린 부분은 없지만, 데브옵스의 정의를 정확히 이해하려면 지속적인 소프트웨어 개발 및 운영, 자동화된 프로세스 개선과 협업 강화라는 목적이 포함되어야 함. [출처: Microsoft Learn - DevOps Overview](https://learn.microsoft.com/en-us/devops/).\n",
      "\n",
      "해당 텍스트 내용에는 명백한 오류는 발견되지 않았습니다.\n",
      "- 텍스트에서 \"데이터를 수집하고 파이프라인 만들고 이런 분야부터 시작해서 학습해서 모델 만들고 배포하고 운영하는 단계까지\"라는 설명은 ML 옵스의 주요 프로세스를 요약하긴 하지만, Azure Machine Learning의 ML 옵스 관련 기능은 데이터 수집 및 파이프라인 자동화 뿐만 아니라 모델 드리프트 모니터링, 재훈련 자동화 등을 포함한다. 텍스트에서 이러한 점이 누락되어 정확한 정보 전달이 부족합니다. [참조: Microsoft Learn](https://learn.microsoft.com/en-us/azure/machine-learning/concept-mlops)\n",
      "- 텍스트에서 \"에멜옵스(MLOps)\"와 관련해 서비스나 오픈소스의 다양성을 언급한 것은 맞지만, MLOps의 정의와 주요 특징 중 하나로 간주되는 **자동화된 워크플로와 지속적인 통합/배포 파이프라인**에 대한 설명이 누락되었습니다. MLOps는 단순히 \"필요한 프로세스를 각자 만드는 것\"이 아니라, 데이터 사이언스와 DevOps의 모범 사례를 결합해 지속 가능한 생산 환경을 구축하는 것이 핵심입니다. [참조: Microsoft Learn - Introduction to MLOps Practices](https://learn.microsoft.com/en-us/azure/machine-learning/concept-model-management-and-deployment)\n",
      "이 텍스트는 MLOps와 관련된 여러 고민의 일반적인 개요를 설명하고 있습니다. 그러나 기능이나 서비스 설명 자체는 명확하게 다뤄지지 않았으므로, Microsoft Learn에서 근거를 찾아볼 만한 지적할 사항이 없습니다.\n",
      "- 클라우드가 \"가장 안정적인 기술들만을 제공한다\"는 설명은 부정확합니다. 클라우드 솔루션은 다양한 기술 수준의 서비스를 제공하며, 사용자는 안정성, 성능, 보안 등 여러 기준을 만족하는 서비스를 선택해야 합니다. 최신 기술이라도 안정적이지 않을 수 있습니다.  \n",
      "  [근거: Microsoft Learn - Cloud Adoption Framework](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/)  \n",
      "\n",
      "- \"클라우드에서는 가장 최신의 기술들을 녹아 있는 곳\"이라는 설명은 과잉 일반화된 주장입니다. 클라우드에서 제공되는 기술은 최신 기술로 제한되지 않으며, 많은 경우 안정성이나 비용을 고려하여 기존 기술도 함께 제공됩니다.  \n",
      "  [근거: Microsoft Learn - Azure services overview](https://learn.microsoft.com/en-us/azure/azure-services-overview/)  \n",
      "- \"클라우드에서 지원되는 여러 가지 서비스들을 이용을 해서 인건비와 노력을 많이 세이브할 수 있다\"는 표현은 일반적으로 맞지만, 이를 MLOps 자동화 전반으로 보편화하면 안 됩니다. Azure MLOps에는 일부 수작업이 여전히 필요하거나 특정 설정이 필요할 수 있습니다. (참고: [Azure MLOps: How it works](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-mlops))  \n",
      "\n",
      "- \"가장 안정적으로 엠엘옵스를 운영할 수 있게 된다\"는 표현은 클라우드 서비스를 사용할 때의 일반적인 이점 중 하나일 수 있으나, 안정적인 운영은 설정 및 대상 워크로드에 크게 의존합니다. 예를 들어, 고도로 커스터마이즈된 워크로드는 추가 검토와 조정이 필요할 수 있습니다. (참고: [Azure MLOps Best Practices](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-best-practices-mlops))  \n",
      "\n",
      "- \"모든 것들을 다 만들어 드릴 수는 없잖아요?\"라는 전달은 맞지만, 더욱 명확한 정보로 다듬을 필요가 있습니다. Azure에서는 MLOps에 대한 다양한 기능 제공 및 자동화를 가능하게 하는 도구를 제공하지만, 완전히 '모든 작업을 다 해야 하는' 상태로 보기는 어렵습니다. (참고: [Azure MLOps Automation](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-automate-mlops))  \n",
      "- Azure Machine Learning의 Python SDK는 MLOps 전체 과정을 운영하고 관리할 수 있는 기능을 제공하지만, \"모델의 각각의 버전들을 연결해서 평가\"라는 설명은 부정확합니다. 모델 버전 관리는 Azure Machine Learning에서 제공되지만, 버전 연결 및 평가라는 기능은 SDK에서 직접적으로 지원되지 않습니다. [참고: Azure Machine Learning Python SDK Documentation](https://learn.microsoft.com/en-us/python/api/overview/azure/ml/)\n",
      "- Azure Machine Learning의 주요 구성 요소 중 하나인 \"Automated ML\"은 프로세스 전체를 자동화하여 최적의 모델을 선택 및 학습시킬 수 있는 도구를 제공하지만, SDK 및 서비스를 통한 고객 맞춤형 배포 타이밍에 초점을 맞춘 기능은 명시적으로 논의되지 않았음. 따라서 설명이 다소 과장되거나 오해를 유발할 수 있음. (출처: [Automated ML - Microsoft Learn](https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml))\n",
      "- **틀린 내용**: \"별도로 임포트를 하거나 하실 필요 없이 네 관련.\"  \n",
      "  **근거**: Azure Machine Learning을 사용하려면 일반적으로 필요한 패키지들을 수동으로 설치하거나 임포트해야 합니다. 이는 특정한 Azure ML 노트북 환경에서는 자동으로 설치 및 구성될 수 있지만, 사용자가 만약 로컬 환경에서 작업 중이라면 관련 패키지(예: `azureml-sdk`)를 임포트해야 합니다. [MS Learn 문서](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-environment)에서는 Python 환경을 준비하고 필요한 패키지를 설치하는 과정을 설명하고 있습니다.  \n",
      "\n",
      "  \n",
      "- \"알파 값이 0.1에서 4.0까지 총 열 번의 반복을 할 수 있게끔 그렇게 했고요\"라는 설명에서 실험 회수와 관련된 특정 메커니즘이나 설정(예: 학습 과정에서 하이퍼파라미터 튜닝)이 명백히 틀렸다면, 그에 대한 정확한 근거를 제시해야 합니다. 알파 값의 범위 및 반복 설정은 일반적으로 사용되는 방법을 나타낼 수 있지만, 해당 부분이 mslearn에서 제공된 문서와 상충되지 않습니다.  \n",
      "\n",
      "- \"클라우드에서 제공되는 강력한 인프라를 이용을 해서\"라는 설명은 일반적으로 Azure Machine Learning에서 제공되는 클라우드 기반 환경을 지칭하는 것으로 보입니다. 특별히 틀린 설명은 아니지만, 더 구체적으로 mslearn에서 제공되는 기능의 정확한 설명을 확인하기 위해 관련 문서를 검토해야 합니다.\n",
      "- \"`모델들은 이미 바이너리로 네, 그렇습니다. 애저 머신러닝 안에 다 세이브가 돼있어요.`\" 부분에서 애저 머신러닝은 모델을 바이너리 파일 형식으로 저장하는 특정 과정이 없으며, 모델은 사용자의 정의에 따라 다양한 형식(Pickle, ONNX 등)으로 저장될 수 있음. [출처: Microsoft Learn - Azure Machine Learning architecture](https://learn.microsoft.com/en-us/azure/machine-learning/concept-azure-machine-learning-architecture)\n",
      "- 해당 설명에서 \"각각의 실험마다 만들어진 모델에 대한 매출액이 따로 따로 준비가 되어있는 것을 볼 수가 있습니다\" 부분은 MS Learn 자료에 따르면 명확히 틀린 것으로 보입니다. MS Learn의 `Azure Machine Learning` 관련 문서에서는 실험 결과가 메트릭스 형태로 제공되고, 모델 성능을 평가하는 요소는 주로 정확도, F1 스코어 등과 같은 통계적 측정값이 포함됩니다. 매출액과 같은 재무적 데이터는 자동으로 결과에 포함되지 않는 것으로 확인되었습니다. (출처: [Azure Machine Learning 결과 분석 문서](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-track-experiments))\n",
      "- \"여기서는 사이킷런을 이용을 했기 때문에 PKL 이라고 하는 확장자로 만들어져 있는 파일들의 목록을 바로 보실 수가 있습니다.\"  \n",
      "  → 사이킷런(Sci-kit Learn)은 ML 모델을 저장할 때 'PKL' 확장자를 사용하는 방식에 대해 직접적인 의존성을 가진 라이브러리가 아닙니다. PKL 파일은 파이썬의 `pickle` 라이브러리를 활용해 모델을 저장하는 방식 중 하나일 뿐, 사이킷런에서 고유한 방식이나 필수 요구사항으로 간주되지는 않습니다. (참고: [mslearn pickle 사용 예제](https://learn.microsoft.com/en-us/training/))  \n",
      "- 실험에 대한 메트릭을 바로 볼 수 있다는 설명은 Azure Machine Learning에서 제공하는 주요 기능과 맥락에 부합합니다. 하지만, \"이 평가하는 방법을 이렇게 돌려보면 이 전체의 내용들을 평가해 보고\"라는 부분은 기능 설명이 명확하지 않습니다. Azure Machine Learning에서 평가 메트릭은 실험 결과를 분석하는 데 사용되며, 이를 돌려보는 기능은 제공되지 않습니다. [출처: Microsoft Learn - Azure Machine Learning Monitoring](https://learn.microsoft.com/en-us/azure/machine-learning/concept-monitoring)\n",
      "- **지적 사항:** \"베스트 모델을 받았다면 이걸 바로 다운로드도 가능하겠죠.\"  \n",
      "  **근거:** Microsoft Learn의 자료에 따르면 Azure Machine Learning에서는 베스트 모델을 자동으로 선택하고 확인할 수 있지만, 모델의 다운로드는 모델을 저장한 후 별도로 수행해야 합니다. 자동 다운로드는 지원되지 않습니다.  \n",
      "  **Citation:** [Microsoft Learn - Azure Machine Learning 자동화된 머신 러닝](https://learn.microsoft.com/azure/machine-learning/concept-automated-ml)\n",
      "\n",
      "- **지적 사항:** \"모델을 만들고 컨테이너라이징해서 네 도커 컨테이너로 만들고 이걸 바로 배포해서 운영.\"  \n",
      "  **근거:** Azure ML에서 모델을 컨테이너에 배포할 수 있지만, 이 과정에서 먼저 머신러닝 모델을 등록하고 환경 및 배포 구성 설정을 해야 합니다. \"바로 배포\"라는 표현은 이러한 과정을 생략하고 즉석으로 가능한 것으로 오해될 수 있습니다.  \n",
      "  **Citation:** [Microsoft Learn - Azure ML에서 모델 배포](https://learn.microsoft.com/azure/machine-learning/how-to-deploy-and-score-model)\n",
      "- 지적 없음: 텍스트에서는 파이썬 및 오픈소스 툴을 활용하여 데이터 정리부터 배포 및 운영까지 전 과정을 처리할 수 있다는 점을 언급하며 설명하고 있는데, 기능 설명 자체는 명확합니다. MS Learn에서 파이썬이 기계 학습 및 데이터 과학 워크플로우에서 광범위하게 사용된다고 명시된 내용과 일치합니다. (참조: [Microsoft Learn - Python Data Science Toolkit](https://learn.microsoft.com/en-us/training/paths/python-for-data-science-machine-learning))\n",
      "- **지적사항**: \"여기서 우리가 만들어진 모델을 바로 배포하고 운영하는 그런 단계까지 이 영상에서 우리가 확인해 보실 수가 있는데\"라는 문구는, 모델 배포와 운영 단계를 단순화하여 설명한 것으로 보입니다. Microsoft Learn에서는 Azure ML 같은 서비스가 모델 배포 및 운영을 지원하지만, 이를 위해서는 적절한 구성, 배포 환경 설정, 모니터링 및 업데이트 과정이 필요하다고 명시합니다. 따라서 \"바로 배포하고 운영\"이라는 표현은 오해를 불러일으킬 수 있습니다.  \n",
      "  - **근거**: [Microsoft Learn - Azure Machine Learning Service](https://learn.microsoft.com/en-us/azure/machine-learning/concept-model-management-deployment)\n",
      "- \"Azure 머신 러닝 서비스에서 노트북스를 이용\"이라는 부분은 오해의 소지가 있습니다. Azure 머신 러닝 서비스에는 Notebook 기능이 포함되어 있지만, 이를 활용하는 방법은 사용자의 설정 및 목표에 따라 다릅니다. MS Learn에 따르면 Azure 머신 러닝은 다양한 개발 환경을 지원하며 그중 Jupyter Notebook 환경도 포함되지만, 반드시 이를 사용해야 하는 것은 아닙니다. [출처: Microsoft Learn - Azure Machine Learning 기본 사항](https://learn.microsoft.com/en-us/azure/machine-learning/)\n",
      "- **지적사항**: \"프로세스를 바로 파이썬 코드로 만들고 운영하는 부분\"이라는 설명은 Azure Machine Learning의 기능에 대한 표현으로 적절하지 않을 수 있습니다. Azure Machine Learning은 주로 데이터 준비, 모델 학습, 평가 및 배포를 지원하는 플랫폼이며, 사용자는 스스로 프로세스를 정의하고 이를 파이썬 코드로 구현해야 합니다. 플랫폼 자체가 프로세스를 자동으로 '바로 파이썬 코드'로 만드는 기능을 제공하지 않습니다.  \n",
      "  **근거**: [Microsoft Learn - Azure Machine Learning](https://learn.microsoft.com/en-us/azure/machine-learning/)\n",
      "\n",
      "**나머지 부분에 대해서는 기능 설명의 명백한 오류로 판단할 근거가 없습니다.**\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'지적할 내용이 없습니다. 작성하신 텍스트가 명백히 틀린 정보를 담고 있지 않습니다. MS Learn 사이트를 기반으로도 이 내용은 사실과 일치합니다. - \"데브옵스는 소프트웨어 개발의 복잡함을 해결하기 위해 발전한 장르\"라는 내용은 틀린 부분은 없지만, 데브옵스의 정의를 정확히 이해하려면 지속적인 소프트웨어 개발 및 운영, 자동화된 프로세스 개선과 협업 강화라는 목적이 포함되어야 함. [출처: Microsoft Learn - DevOps Overview](https://learn.microsoft.com/en-us/devops/).\\n\\n해당 텍스트 내용에는 명백한 오류는 발견되지 않았습니다. - 텍스트에서 \"데이터를 수집하고 파이프라인 만들고 이런 분야부터 시작해서 학습해서 모델 만들고 배포하고 운영하는 단계까지\"라는 설명은 ML 옵스의 주요 프로세스를 요약하긴 하지만, Azure Machine Learning의 ML 옵스 관련 기능은 데이터 수집 및 파이프라인 자동화 뿐만 아니라 모델 드리프트 모니터링, 재훈련 자동화 등을 포함한다. 텍스트에서 이러한 점이 누락되어 정확한 정보 전달이 부족합니다. [참조: Microsoft Learn](https://learn.microsoft.com/en-us/azure/machine-learning/concept-mlops) - 텍스트에서 \"에멜옵스(MLOps)\"와 관련해 서비스나 오픈소스의 다양성을 언급한 것은 맞지만, MLOps의 정의와 주요 특징 중 하나로 간주되는 **자동화된 워크플로와 지속적인 통합/배포 파이프라인**에 대한 설명이 누락되었습니다. MLOps는 단순히 \"필요한 프로세스를 각자 만드는 것\"이 아니라, 데이터 사이언스와 DevOps의 모범 사례를 결합해 지속 가능한 생산 환경을 구축하는 것이 핵심입니다. [참조: Microsoft Learn - Introduction to MLOps Practices](https://learn.microsoft.com/en-us/azure/machine-learning/concept-model-management-and-deployment) 이 텍스트는 MLOps와 관련된 여러 고민의 일반적인 개요를 설명하고 있습니다. 그러나 기능이나 서비스 설명 자체는 명확하게 다뤄지지 않았으므로, Microsoft Learn에서 근거를 찾아볼 만한 지적할 사항이 없습니다. - 클라우드가 \"가장 안정적인 기술들만을 제공한다\"는 설명은 부정확합니다. 클라우드 솔루션은 다양한 기술 수준의 서비스를 제공하며, 사용자는 안정성, 성능, 보안 등 여러 기준을 만족하는 서비스를 선택해야 합니다. 최신 기술이라도 안정적이지 않을 수 있습니다.  \\n  [근거: Microsoft Learn - Cloud Adoption Framework](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/)  \\n\\n- \"클라우드에서는 가장 최신의 기술들을 녹아 있는 곳\"이라는 설명은 과잉 일반화된 주장입니다. 클라우드에서 제공되는 기술은 최신 기술로 제한되지 않으며, 많은 경우 안정성이나 비용을 고려하여 기존 기술도 함께 제공됩니다.  \\n  [근거: Microsoft Learn - Azure services overview](https://learn.microsoft.com/en-us/azure/azure-services-overview/)   - \"클라우드에서 지원되는 여러 가지 서비스들을 이용을 해서 인건비와 노력을 많이 세이브할 수 있다\"는 표현은 일반적으로 맞지만, 이를 MLOps 자동화 전반으로 보편화하면 안 됩니다. Azure MLOps에는 일부 수작업이 여전히 필요하거나 특정 설정이 필요할 수 있습니다. (참고: [Azure MLOps: How it works](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-mlops))  \\n\\n- \"가장 안정적으로 엠엘옵스를 운영할 수 있게 된다\"는 표현은 클라우드 서비스를 사용할 때의 일반적인 이점 중 하나일 수 있으나, 안정적인 운영은 설정 및 대상 워크로드에 크게 의존합니다. 예를 들어, 고도로 커스터마이즈된 워크로드는 추가 검토와 조정이 필요할 수 있습니다. (참고: [Azure MLOps Best Practices](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-best-practices-mlops))  \\n\\n- \"모든 것들을 다 만들어 드릴 수는 없잖아요?\"라는 전달은 맞지만, 더욱 명확한 정보로 다듬을 필요가 있습니다. Azure에서는 MLOps에 대한 다양한 기능 제공 및 자동화를 가능하게 하는 도구를 제공하지만, 완전히 \\'모든 작업을 다 해야 하는\\' 상태로 보기는 어렵습니다. (참고: [Azure MLOps Automation](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-automate-mlops))   - Azure Machine Learning의 Python SDK는 MLOps 전체 과정을 운영하고 관리할 수 있는 기능을 제공하지만, \"모델의 각각의 버전들을 연결해서 평가\"라는 설명은 부정확합니다. 모델 버전 관리는 Azure Machine Learning에서 제공되지만, 버전 연결 및 평가라는 기능은 SDK에서 직접적으로 지원되지 않습니다. [참고: Azure Machine Learning Python SDK Documentation](https://learn.microsoft.com/en-us/python/api/overview/azure/ml/) - Azure Machine Learning의 주요 구성 요소 중 하나인 \"Automated ML\"은 프로세스 전체를 자동화하여 최적의 모델을 선택 및 학습시킬 수 있는 도구를 제공하지만, SDK 및 서비스를 통한 고객 맞춤형 배포 타이밍에 초점을 맞춘 기능은 명시적으로 논의되지 않았음. 따라서 설명이 다소 과장되거나 오해를 유발할 수 있음. (출처: [Automated ML - Microsoft Learn](https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml)) - **틀린 내용**: \"별도로 임포트를 하거나 하실 필요 없이 네 관련.\"  \\n  **근거**: Azure Machine Learning을 사용하려면 일반적으로 필요한 패키지들을 수동으로 설치하거나 임포트해야 합니다. 이는 특정한 Azure ML 노트북 환경에서는 자동으로 설치 및 구성될 수 있지만, 사용자가 만약 로컬 환경에서 작업 중이라면 관련 패키지(예: `azureml-sdk`)를 임포트해야 합니다. [MS Learn 문서](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-environment)에서는 Python 환경을 준비하고 필요한 패키지를 설치하는 과정을 설명하고 있습니다.  \\n\\n   - \"알파 값이 0.1에서 4.0까지 총 열 번의 반복을 할 수 있게끔 그렇게 했고요\"라는 설명에서 실험 회수와 관련된 특정 메커니즘이나 설정(예: 학습 과정에서 하이퍼파라미터 튜닝)이 명백히 틀렸다면, 그에 대한 정확한 근거를 제시해야 합니다. 알파 값의 범위 및 반복 설정은 일반적으로 사용되는 방법을 나타낼 수 있지만, 해당 부분이 mslearn에서 제공된 문서와 상충되지 않습니다.  \\n\\n- \"클라우드에서 제공되는 강력한 인프라를 이용을 해서\"라는 설명은 일반적으로 Azure Machine Learning에서 제공되는 클라우드 기반 환경을 지칭하는 것으로 보입니다. 특별히 틀린 설명은 아니지만, 더 구체적으로 mslearn에서 제공되는 기능의 정확한 설명을 확인하기 위해 관련 문서를 검토해야 합니다. - \"`모델들은 이미 바이너리로 네, 그렇습니다. 애저 머신러닝 안에 다 세이브가 돼있어요.`\" 부분에서 애저 머신러닝은 모델을 바이너리 파일 형식으로 저장하는 특정 과정이 없으며, 모델은 사용자의 정의에 따라 다양한 형식(Pickle, ONNX 등)으로 저장될 수 있음. [출처: Microsoft Learn - Azure Machine Learning architecture](https://learn.microsoft.com/en-us/azure/machine-learning/concept-azure-machine-learning-architecture) - 해당 설명에서 \"각각의 실험마다 만들어진 모델에 대한 매출액이 따로 따로 준비가 되어있는 것을 볼 수가 있습니다\" 부분은 MS Learn 자료에 따르면 명확히 틀린 것으로 보입니다. MS Learn의 `Azure Machine Learning` 관련 문서에서는 실험 결과가 메트릭스 형태로 제공되고, 모델 성능을 평가하는 요소는 주로 정확도, F1 스코어 등과 같은 통계적 측정값이 포함됩니다. 매출액과 같은 재무적 데이터는 자동으로 결과에 포함되지 않는 것으로 확인되었습니다. (출처: [Azure Machine Learning 결과 분석 문서](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-track-experiments)) - \"여기서는 사이킷런을 이용을 했기 때문에 PKL 이라고 하는 확장자로 만들어져 있는 파일들의 목록을 바로 보실 수가 있습니다.\"  \\n  → 사이킷런(Sci-kit Learn)은 ML 모델을 저장할 때 \\'PKL\\' 확장자를 사용하는 방식에 대해 직접적인 의존성을 가진 라이브러리가 아닙니다. PKL 파일은 파이썬의 `pickle` 라이브러리를 활용해 모델을 저장하는 방식 중 하나일 뿐, 사이킷런에서 고유한 방식이나 필수 요구사항으로 간주되지는 않습니다. (참고: [mslearn pickle 사용 예제](https://learn.microsoft.com/en-us/training/))   - 실험에 대한 메트릭을 바로 볼 수 있다는 설명은 Azure Machine Learning에서 제공하는 주요 기능과 맥락에 부합합니다. 하지만, \"이 평가하는 방법을 이렇게 돌려보면 이 전체의 내용들을 평가해 보고\"라는 부분은 기능 설명이 명확하지 않습니다. Azure Machine Learning에서 평가 메트릭은 실험 결과를 분석하는 데 사용되며, 이를 돌려보는 기능은 제공되지 않습니다. [출처: Microsoft Learn - Azure Machine Learning Monitoring](https://learn.microsoft.com/en-us/azure/machine-learning/concept-monitoring) - **지적 사항:** \"베스트 모델을 받았다면 이걸 바로 다운로드도 가능하겠죠.\"  \\n  **근거:** Microsoft Learn의 자료에 따르면 Azure Machine Learning에서는 베스트 모델을 자동으로 선택하고 확인할 수 있지만, 모델의 다운로드는 모델을 저장한 후 별도로 수행해야 합니다. 자동 다운로드는 지원되지 않습니다.  \\n  **Citation:** [Microsoft Learn - Azure Machine Learning 자동화된 머신 러닝](https://learn.microsoft.com/azure/machine-learning/concept-automated-ml)\\n\\n- **지적 사항:** \"모델을 만들고 컨테이너라이징해서 네 도커 컨테이너로 만들고 이걸 바로 배포해서 운영.\"  \\n  **근거:** Azure ML에서 모델을 컨테이너에 배포할 수 있지만, 이 과정에서 먼저 머신러닝 모델을 등록하고 환경 및 배포 구성 설정을 해야 합니다. \"바로 배포\"라는 표현은 이러한 과정을 생략하고 즉석으로 가능한 것으로 오해될 수 있습니다.  \\n  **Citation:** [Microsoft Learn - Azure ML에서 모델 배포](https://learn.microsoft.com/azure/machine-learning/how-to-deploy-and-score-model) - 지적 없음: 텍스트에서는 파이썬 및 오픈소스 툴을 활용하여 데이터 정리부터 배포 및 운영까지 전 과정을 처리할 수 있다는 점을 언급하며 설명하고 있는데, 기능 설명 자체는 명확합니다. MS Learn에서 파이썬이 기계 학습 및 데이터 과학 워크플로우에서 광범위하게 사용된다고 명시된 내용과 일치합니다. (참조: [Microsoft Learn - Python Data Science Toolkit](https://learn.microsoft.com/en-us/training/paths/python-for-data-science-machine-learning)) - **지적사항**: \"여기서 우리가 만들어진 모델을 바로 배포하고 운영하는 그런 단계까지 이 영상에서 우리가 확인해 보실 수가 있는데\"라는 문구는, 모델 배포와 운영 단계를 단순화하여 설명한 것으로 보입니다. Microsoft Learn에서는 Azure ML 같은 서비스가 모델 배포 및 운영을 지원하지만, 이를 위해서는 적절한 구성, 배포 환경 설정, 모니터링 및 업데이트 과정이 필요하다고 명시합니다. 따라서 \"바로 배포하고 운영\"이라는 표현은 오해를 불러일으킬 수 있습니다.  \\n  - **근거**: [Microsoft Learn - Azure Machine Learning Service](https://learn.microsoft.com/en-us/azure/machine-learning/concept-model-management-deployment) - \"Azure 머신 러닝 서비스에서 노트북스를 이용\"이라는 부분은 오해의 소지가 있습니다. Azure 머신 러닝 서비스에는 Notebook 기능이 포함되어 있지만, 이를 활용하는 방법은 사용자의 설정 및 목표에 따라 다릅니다. MS Learn에 따르면 Azure 머신 러닝은 다양한 개발 환경을 지원하며 그중 Jupyter Notebook 환경도 포함되지만, 반드시 이를 사용해야 하는 것은 아닙니다. [출처: Microsoft Learn - Azure Machine Learning 기본 사항](https://learn.microsoft.com/en-us/azure/machine-learning/) - **지적사항**: \"프로세스를 바로 파이썬 코드로 만들고 운영하는 부분\"이라는 설명은 Azure Machine Learning의 기능에 대한 표현으로 적절하지 않을 수 있습니다. Azure Machine Learning은 주로 데이터 준비, 모델 학습, 평가 및 배포를 지원하는 플랫폼이며, 사용자는 스스로 프로세스를 정의하고 이를 파이썬 코드로 구현해야 합니다. 플랫폼 자체가 프로세스를 자동으로 \\'바로 파이썬 코드\\'로 만드는 기능을 제공하지 않습니다.  \\n  **근거**: [Microsoft Learn - Azure Machine Learning](https://learn.microsoft.com/en-us/azure/machine-learning/)\\n\\n**나머지 부분에 대해서는 기능 설명의 명백한 오류로 판단할 근거가 없습니다.** '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_feedback_flow(refined_chunks[1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitch Purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pitch_purpose(recognized_chunks):\n",
    "    \"\"\"\n",
    "    Function to retrieve the pitch purpose by analyzing the first two chunks of recognized text.\n",
    "    \n",
    "    Args:\n",
    "        recognized_chunks (list): List of recognized text chunks.\n",
    "    Returns:\n",
    "        pitch_purpose (str): Retrieved pitch purpose.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(recognized_chunks) < 2:\n",
    "        return \"Microsoft 세일즈 피치\"\n",
    "        # raise ValueError(\"Not enough recognized chunks to determine pitch purpose.\")\n",
    "    \n",
    "    # Combine the first two chunks for analysis\n",
    "    combined_chunks = \" \".join(recognized_chunks[:2])\n",
    "    \n",
    "    # Define system and user prompts for GPT\n",
    "    system_prompt = \"세일즈 피치의 목적을 판단해줘.\"\n",
    "    user_prompt = f\"다음 내용이 마이크로소프트의 어떤 서비스에 대한 피치인지 판단해줘. 부연 설명 없이 피치 목적만을 리턴해줘.: {combined_chunks}\"\n",
    "    \n",
    "    # Call GPT to retrieve the pitch purpose\n",
    "    pitch_purpose = call_gpt(system_prompt, user_prompt)\n",
    "    \n",
    "    return pitch_purpose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'애저 머신 러닝 서비스 홍보.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pitch_purpose(refined_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evalai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
